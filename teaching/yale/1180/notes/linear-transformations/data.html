<header><div id="logo"><a href="/home" tabindex="-1"><img src="/graphics/general-icons/logo.webp" alt="Logo" tabindex="1"></img></a></div><div style="height: 20px"></div><h1 class="heading-text">Section 13: Linear Transformations</h1></header><main><section><div class="text-buttons nav-buttons"><div class="focus-on-child" tabindex="1"><button class="text-button linked-text-button nav-button previous-nav-button" type="button" tabindex="-1">Previous</button></div><div class="focus-on-child" tabindex="1"><button class="text-button linked-text-button nav-button home-nav-button" type="button" tabindex="-1">Home</button></div><div class="focus-on-child" tabindex="1"><button class="text-button linked-text-button nav-button next-nav-button" type="button" tabindex="-1">Next</button></div></div><p class="body-text">A common trend in math is to define a new type of object (e.g. a vector), develop some properties about it, and then begin to study functions (often called <strong>maps</strong>) that operate on those objects. Depending on the structure of the objects in question, the characteristics of the maps we want to study are slightly different. Here, those objects are vectors in <span class="tex-holder inline-math" data-source-tex="\mathbb{R}^n">$\mathbb{R}^n$,</span> and the maps will be quite similar to matrices.</p><p class="body-text">As we&#x2019;ve discussed, an <span class="tex-holder inline-math" data-source-tex="m \times n">$m \times n$</span> matrix <span class="tex-holder inline-math" data-source-tex="A">$A$</span> is a function that takes in length-<span class="tex-holder inline-math" data-source-tex="n">$n$</span> vectors and gives back length-<span class="tex-holder inline-math" data-source-tex="m">$m$</span> ones, so we can write <span class="tex-holder inline-math" data-source-tex="A : \mathbb{R}^n \to \mathbb{R}^m">$A : \mathbb{R}^n \to \mathbb{R}^m$.</span> We&#x2019;ve also seen that for any vectors <span class="tex-holder inline-math" data-source-tex="\vec{v}, \vec{w} \in \mathbb{R}^n">$\vec{v}, \vec{w} \in \mathbb{R}^n$,</span></p><p class="body-text" style="text-align: center; line-height: 0"><span class="tex-holder" style="padding: 8px" data-source-tex="$$[NEWLINE][TAB]A(\vec{v} + \vec{w}) = A\vec{v} + A\vec{w},[NEWLINE]$$">$$\begin{align*}A(\vec{v} + \vec{w}) = A\vec{v} + A\vec{w},\end{align*}$$</span></p><p class="body-text">and <span class="tex-holder inline-math" data-source-tex="A(c\vec{v}) = cA\vec{v}">$A(c\vec{v}) = cA\vec{v}$</span> for any constant <span class="tex-holder inline-math" data-source-tex="c">$c$.</span> Inspired by these properties, let&#x2019;s look at functions that are <em>defined</em> this way: ones that factor through addition and scalar multiplication of vectors.</p><div class="notes-def notes-environment"><div class="notes-def-title notes-title">Definition: linear transformation</div><p class="body-text">A <strong>linear transformation</strong>, or <strong>linear map</strong>, from <span class="tex-holder inline-math" data-source-tex="\mathbb{R}^n">$\mathbb{R}^n$</span> to <span class="tex-holder inline-math" data-source-tex="\mathbb{R}^m">$\mathbb{R}^m$</span> is a function <span class="tex-holder inline-math" data-source-tex="T: \mathbb{R}^n \to \mathbb{R}^m">$T: \mathbb{R}^n \to \mathbb{R}^m$,</span> such that</p><p class="body-text numbered-list-item">1. For any two vectors <span class="tex-holder inline-math" data-source-tex="\vec{v}, \vec{w} \in \mathbb{R}^n">$\vec{v}, \vec{w} \in \mathbb{R}^n$,</span> <span class="tex-holder inline-math" data-source-tex="T(\vec{v} + \vec{w}) = T(\vec{v}) + T(\vec{w})">$T(\vec{v} + \vec{w}) = T(\vec{v}) + T(\vec{w})$.</span></p><p class="body-text numbered-list-item">2. For any vector <span class="tex-holder inline-math" data-source-tex="\vec{n} \in \mathbb{R}^n">$\vec{n} \in \mathbb{R}^n$</span> and any constant <span class="tex-holder inline-math" data-source-tex="c">$c$,</span> <span class="tex-holder inline-math" data-source-tex="T(c\vec{v}) = cT(\vec{v})">$T(c\vec{v}) = cT(\vec{v})$.</span></p></div><p class="body-text">First of all, one immediate property of any linear transformation <span class="tex-holder inline-math" data-source-tex="T">$T$</span> is that it must send the zero vector to itself:</p><p class="body-text" style="text-align: center; line-height: 0"><span class="tex-holder" style="padding: 8px" data-source-tex="$$[NEWLINE][TAB]T(\vec{0}) = T(0 \cdot \vec{0}) = 0 \cdot T(\vec{0}) = \vec{0}.[NEWLINE]$$">$$\begin{align*}T(\vec{0}) = T(0 \cdot \vec{0}) = 0 \cdot T(\vec{0}) = \vec{0}.\end{align*}$$</span></p><p class="body-text">Linear transformations from <span class="tex-holder inline-math" data-source-tex="\mathbb{R}">$\mathbb{R}$</span> to <span class="tex-holder inline-math" data-source-tex="\mathbb{R}">$\mathbb{R}$</span> aren&#x2019;t very exciting: if <span class="tex-holder inline-math" data-source-tex="T">$T$</span> is such a linear transformation, then</p><p class="body-text" style="text-align: center; line-height: 0"><span class="tex-holder" style="padding: 8px" data-source-tex="$$[NEWLINE][TAB]T(x) = T(x \cdot 1) = x T(1),[NEWLINE]$$">$$\begin{align*}T(x) = T(x \cdot 1) = x T(1),\end{align*}$$</span></p><p class="body-text">so as soon as we know what <span class="tex-holder inline-math" data-source-tex="T(1)">$T(1)$</span> is, every other output of <span class="tex-holder inline-math" data-source-tex="T">$T$</span> is fixed. If <span class="tex-holder inline-math" data-source-tex="a = T(1)">$a = T(1)$,</span> then <span class="tex-holder inline-math" data-source-tex="T(x) = ax">$T(x) = ax$,</span> so linear transformations <span class="tex-holder inline-math" data-source-tex="\mathbb{R} \to \mathbb{R}">$\mathbb{R} \to \mathbb{R}$</span> are just lines through the origin. It might seem like needless attention to detail, but let&#x2019;s take a moment to graph these.</p><div class="desmos-border"><div id="1dLinearTransformation" class="desmos-container"></div></div><p class="body-text">Here, the input vector (i.e. the number <span class="tex-holder inline-math" data-source-tex="1">$1$)</span> is colored purple, and the output vector colored blue. The value of <span class="tex-holder inline-math" data-source-tex="a">$a$</span> is given by the red point. While we normally plot functions with inputs on one axis and outputs on another, we&#x2019;re using the <span class="tex-holder inline-math" data-source-tex="x">$x$-axis</span> here for both input and output. That&#x2019;s for two reasons: first, it&#x2019;s foreshadowing for the two-dimensional case we&#x2019;re about to consider, and more importantly, it reflects the fact that we don&#x2019;t need to see other input-output pairs to completely understand the effects of a linear map. Any other input, like <span class="tex-holder inline-math" data-source-tex="-2">$-2$,</span> is sent to <span class="tex-holder inline-math" data-source-tex="-2">$-2$</span> times whatever <span class="tex-holder inline-math" data-source-tex="1">$1$</span> is sent to &mdash; that&#x2019;s what it means to be a linear map.</p><p class="body-text">When we&#x2019;re not confined to a single input and output variable, linear transformations become much more interesting. Let&#x2019;s take a linear map <span class="tex-holder inline-math" data-source-tex="T : \mathbb{R}^2 \to \mathbb{R}^2">$T : \mathbb{R}^2 \to \mathbb{R}^2$.</span> By using the properties of linear maps, we can reduce the problem of evaluating it on a generic vector to just two very specific ones:</p><p class="body-text" style="text-align: center; line-height: 0"><span class="tex-holder" style="padding: 8px" data-source-tex="\begin{align*}[NEWLINE][TAB]T\left( \left[\begin{array}{c} a  \\ b \end{array}\right] \right) &= T\left( \left[\begin{array}{c} a \\ 0 \end{array}\right] + \left[\begin{array}{c} 0 \\ b \end{array}\right] \right)\\[NEWLINE][TAB]&= T\left( \left[\begin{array}{c} a \\ 0 \end{array}\right] \right) + T \left( \left[\begin{array}{c} 0 \\ b \end{array}\right] \right)\\[NEWLINE][TAB]&= T\left( a \left[\begin{array}{c} 1 \\ 0 \end{array}\right] \right) + T \left( b \left[\begin{array}{c} 0 \\ 1 \end{array}\right] \right)\\[NEWLINE][TAB]&= a T\left( \left[\begin{array}{c} 1 \\ 0 \end{array}\right] \right) + b T \left( \left[\begin{array}{c} 0 \\ 1 \end{array}\right] \right).[NEWLINE]\end{align*}">$$\begin{align*}T\left( \left[\begin{array}{c} a  \\ b \end{array}\right] \right) &= T\left( \left[\begin{array}{c} a \\ 0 \end{array}\right] + \left[\begin{array}{c} 0 \\ b \end{array}\right] \right)\\[4px]&= T\left( \left[\begin{array}{c} a \\ 0 \end{array}\right] \right) + T \left( \left[\begin{array}{c} 0 \\ b \end{array}\right] \right)\\[4px]&= T\left( a \left[\begin{array}{c} 1 \\ 0 \end{array}\right] \right) + T \left( b \left[\begin{array}{c} 0 \\ 1 \end{array}\right] \right)\\[4px]&= a T\left( \left[\begin{array}{c} 1 \\ 0 \end{array}\right] \right) + b T \left( \left[\begin{array}{c} 0 \\ 1 \end{array}\right] \right).\end{align*}$$</span></p><p class="body-text">So as soon as we know where <span class="tex-holder inline-math" data-source-tex="T">$T$</span> sends <span class="tex-holder inline-math" data-source-tex="\left[\begin{array}{c} 1 \\ 0 \end{array}\right]">$\left[\begin{array}{c} 1 \\ 0 \end{array}\right]$</span> and <span class="tex-holder inline-math" data-source-tex="\left[\begin{array}{c} 0 \\ 1 \end{array}\right]">$\left[\begin{array}{c} 0 \\ 1 \end{array}\right]$,</span> finding where it sends any other vector is as simple as taking a linear combination of those two outputs.</p><div class="desmos-border"><div id="2dLinearTransformation" class="desmos-container"></div></div><p class="body-text">There&#x2019;s a lot going on in this graph, so let&#x2019;s go through it carefully. The red and blue vectors that can&#x2019;t be dragged are <span class="tex-holder inline-math" data-source-tex="\left[\begin{array}{c} 1 \\ 0 \end{array}\right]">$\left[\begin{array}{c} 1 \\ 0 \end{array}\right]$</span> and <span class="tex-holder inline-math" data-source-tex="\left[\begin{array}{c} 0 \\ 1 \end{array}\right]">$\left[\begin{array}{c} 0 \\ 1 \end{array}\right]$,</span> and the ones that can be dragged are the corresponding outputs &mdash; i.e. <span class="tex-holder inline-math" data-source-tex="T \left( \left[\begin{array}{c} 1 \\ 0 \end{array}\right] \right)">$T \left( \left[\begin{array}{c} 1 \\ 0 \end{array}\right] \right)$</span> and <span class="tex-holder inline-math" data-source-tex="T \left( \left[\begin{array}{c} 0 \\ 1 \end{array}\right] \right)">$T \left( \left[\begin{array}{c} 0 \\ 1 \end{array}\right] \right)$.</span> To give them names, let&#x2019;s say those output vectors are</p><p class="body-text" style="text-align: center; line-height: 0"><span class="tex-holder" style="padding: 8px" data-source-tex="\begin{align*}[NEWLINE][TAB]T \left( \left[\begin{array}{c} 1 \\ 0 \end{array}\right] \right) &= \left[\begin{array}{c} a_{11} \\ a_{21} \end{array}\right]\\[NEWLINE][TAB]T \left( \left[\begin{array}{c} 0 \\ 1 \end{array}\right] \right) &= \left[\begin{array}{c} a_{12} \\ a_{22} \end{array}\right].[NEWLINE]\end{align*}">$$\begin{align*}T \left( \left[\begin{array}{c} 1 \\ 0 \end{array}\right] \right) &= \left[\begin{array}{c} a_{11} \\ a_{21} \end{array}\right]\\[4px]T \left( \left[\begin{array}{c} 0 \\ 1 \end{array}\right] \right) &= \left[\begin{array}{c} a_{12} \\ a_{22} \end{array}\right].\end{align*}$$</span></p><p class="body-text">As we just figured out, the entire behavior of <span class="tex-holder inline-math" data-source-tex="T">$T$</span> is determined once those four values are chosen. The draggable purple vector <span class="tex-holder inline-math" data-source-tex="\left[\begin{array}{c} x_1 \\ x_2 \end{array}\right]">$\left[\begin{array}{c} x_1 \\ x_2 \end{array}\right]$</span> is fed into <span class="tex-holder inline-math" data-source-tex="T">$T$,</span> and the output is the non-draggable purple vector. To make this all a lot more concrete, let&#x2019;s work through an example.</p><div class="notes-ex notes-environment"><div class="notes-ex-title notes-title">Example: linear transformation</div><p class="body-text">Suppose <span class="tex-holder inline-math" data-source-tex="T : \mathbb{R}^2 \to \mathbb{R}^2">$T : \mathbb{R}^2 \to \mathbb{R}^2$</span> is a linear transformation satisfying</p><p class="body-text" style="text-align: center; line-height: 0"><span class="tex-holder" style="padding: 8px" data-source-tex="\begin{align*}[NEWLINE][TAB]T \left( \left[\begin{array}{c} 1 \\ 0 \end{array}\right] \right) &= \left[\begin{array}{c} 1 \\ 3 \end{array}\right]\\[NEWLINE][TAB]T \left( \left[\begin{array}{c} 0 \\ 1 \end{array}\right] \right) &= \left[\begin{array}{c} 0 \\ -2 \end{array}\right].[NEWLINE]\end{align*}">$$\begin{align*}T \left( \left[\begin{array}{c} 1 \\ 0 \end{array}\right] \right) &= \left[\begin{array}{c} 1 \\ 3 \end{array}\right]\\[4px]T \left( \left[\begin{array}{c} 0 \\ 1 \end{array}\right] \right) &= \left[\begin{array}{c} 0 \\ -2 \end{array}\right].\end{align*}$$</span></p><p class="body-text">Find <span class="tex-holder inline-math" data-source-tex="T \left( \left[\begin{array}{c} 3 \\ 4 \end{array}\right] \right)">$T \left( \left[\begin{array}{c} 3 \\ 4 \end{array}\right] \right)$.</span></p><div class="solution"></div><p class="body-text">Since <span class="tex-holder inline-math" data-source-tex="T">$T$</span> is linear, we can expand that last expression quite a bit:</p><p class="body-text" style="text-align: center; line-height: 0"><span class="tex-holder" style="padding: 8px" data-source-tex="\begin{align*}[NEWLINE][TAB]T \left( \left[\begin{array}{c} 3 \\ 4 \end{array}\right] \right) &= 3 T \left( \left[\begin{array}{c} 1 \\ 0 \end{array}\right] \right) + 4 T \left( \left[\begin{array}{c} 0 \\ 1 \end{array}\right] \right)\\[NEWLINE][TAB]&= 3 \left[\begin{array}{c} 1 \\ 3 \end{array}\right] + 4 \left[\begin{array}{c} 0 \\ -2 \end{array}\right]\\[NEWLINE][TAB]&= \left[\begin{array}{c} 3 \\ 1 \end{array}\right].[NEWLINE]\end{align*}">$$\begin{align*}T \left( \left[\begin{array}{c} 3 \\ 4 \end{array}\right] \right) &= 3 T \left( \left[\begin{array}{c} 1 \\ 0 \end{array}\right] \right) + 4 T \left( \left[\begin{array}{c} 0 \\ 1 \end{array}\right] \right)\\[4px]&= 3 \left[\begin{array}{c} 1 \\ 3 \end{array}\right] + 4 \left[\begin{array}{c} 0 \\ -2 \end{array}\right]\\[4px]&= \left[\begin{array}{c} 3 \\ 1 \end{array}\right].\end{align*}$$</span></p><p class="body-text">In the previous graph, setting <span class="tex-holder inline-math" data-source-tex="a_{11} = 1">$a_{11} = 1$,</span> <span class="tex-holder inline-math" data-source-tex="a_{21} = 3">$a_{21} = 3$,</span> <span class="tex-holder inline-math" data-source-tex="a_{12} = 0">$a_{12} = 0$,</span> and <span class="tex-holder inline-math" data-source-tex="a_{22} = -2">$a_{22} = -2$</span> results in a linear map <span class="tex-holder inline-math" data-source-tex="T">$T$</span> that sends <span class="tex-holder inline-math" data-source-tex="\left[\begin{array}{c} 3 \\ 4 \end{array}\right]">$\left[\begin{array}{c} 3 \\ 4 \end{array}\right]$</span> to <span class="tex-holder inline-math" data-source-tex="\left[\begin{array}{c} 3 \\ 1 \end{array}\right]">$\left[\begin{array}{c} 3 \\ 1 \end{array}\right]$.</span> Drag the purple point to <span class="tex-holder inline-math" data-source-tex="(3, 4)">$(3, 4)$</span> to check!</p></div><div class="notes-exc notes-environment"><div class="notes-exc-title notes-title">Exercise: linear transformation</div><p class="body-text">Suppose <span class="tex-holder inline-math" data-source-tex="S : \mathbb{R}^3 \to \mathbb{R}^2">$S : \mathbb{R}^3 \to \mathbb{R}^2$</span> is a linear transformation satisfying</p><p class="body-text" style="text-align: center; line-height: 0"><span class="tex-holder" style="padding: 8px" data-source-tex="$$[NEWLINE][TAB]S \left( \left[\begin{array}{c} 1 \\ 0 \\ 1 \end{array}\right] \right) = \left[\begin{array}{c} 1 \\ 1 \end{array}\right]\\[NEWLINE][TAB]S \left( \left[\begin{array}{c} 0 \\ 1 \\ 1 \end{array}\right] \right) = \left[\begin{array}{c} 3 \\ 1 \end{array}\right]\\[NEWLINE][TAB]S \left( \left[\begin{array}{c} 0 \\ 0 \\ 2 \end{array}\right] \right) = \left[\begin{array}{c} 6 \\ 2 \end{array}\right].[NEWLINE]$$">$$\begin{align*}S \left( \left[\begin{array}{c} 1 \\ 0 \\ 1 \end{array}\right] \right) = \left[\begin{array}{c} 1 \\ 1 \end{array}\right]\\[4px]S \left( \left[\begin{array}{c} 0 \\ 1 \\ 1 \end{array}\right] \right) = \left[\begin{array}{c} 3 \\ 1 \end{array}\right]\\[4px]S \left( \left[\begin{array}{c} 0 \\ 0 \\ 2 \end{array}\right] \right) = \left[\begin{array}{c} 6 \\ 2 \end{array}\right].\end{align*}$$</span></p><p class="body-text">Find <span class="tex-holder inline-math" data-source-tex="S \left( \left[\begin{array}{c} 1 \\ 2 \\ 3 \end{array}\right] \right)">$S \left( \left[\begin{array}{c} 1 \\ 2 \\ 3 \end{array}\right] \right)$.</span></p></div><p class="body-text">In so many symbols, sending a vector <span class="tex-holder inline-math" data-source-tex="\left[\begin{array}{c} x_1 \\ x_2 \end{array}\right]">$\left[\begin{array}{c} x_1 \\ x_2 \end{array}\right]$</span> through <span class="tex-holder inline-math" data-source-tex="T">$T$</span> results in a linear combination of <span class="tex-holder inline-math" data-source-tex="T \left( \left[\begin{array}{c} 1 \\ 0 \end{array}\right] \right)">$T \left( \left[\begin{array}{c} 1 \\ 0 \end{array}\right] \right)$</span> and <span class="tex-holder inline-math" data-source-tex="T \left( \left[\begin{array}{c} 0 \\ 1 \end{array}\right] \right)">$T \left( \left[\begin{array}{c} 0 \\ 1 \end{array}\right] \right)$.</span> In fact, that&#x2019;s what it means for <span class="tex-holder inline-math" data-source-tex="T">$T$</span> to be a linear map in the first place.</p><p class="body-text">Let&#x2019;s fully work the <span class="tex-holder inline-math" data-source-tex="2 \times 2">$2 \times 2$</span> case through in general. We&#x2019;ve already given names to all three relevant vectors: the results of <span class="tex-holder inline-math" data-source-tex="T">$T$</span> applied to the two unit coordinate vectors, and the generic purple input vector. Applying <span class="tex-holder inline-math" data-source-tex="T">$T$</span> to it, we have</p><p class="body-text" style="text-align: center; line-height: 0"><span class="tex-holder" style="padding: 8px" data-source-tex="\begin{align*}[NEWLINE][TAB]T \left( \left[\begin{array}{c} x_1 \\ x_2 \end{array}\right] \right) &= x_1 T \left( \left[\begin{array}{c} 1 \\ 0 \end{array}\right] \right) + x_2 T \left( \left[\begin{array}{c} 0 \\ 1 \end{array}\right] \right)\\[NEWLINE][TAB]&= x_1 \left[\begin{array}{c} a_{11} \\ a_{21} \end{array}\right] + x_2 \left[\begin{array}{c} a_{12} \\ a_{22} \end{array}\right].[NEWLINE]\end{align*}">$$\begin{align*}T \left( \left[\begin{array}{c} x_1 \\ x_2 \end{array}\right] \right) &= x_1 T \left( \left[\begin{array}{c} 1 \\ 0 \end{array}\right] \right) + x_2 T \left( \left[\begin{array}{c} 0 \\ 1 \end{array}\right] \right)\\[4px]&= x_1 \left[\begin{array}{c} a_{11} \\ a_{21} \end{array}\right] + x_2 \left[\begin{array}{c} a_{12} \\ a_{22} \end{array}\right].\end{align*}$$</span></p><p class="body-text">Now that looks a whole lot like matrix multiplication! Specifically, it&#x2019;s a matrix times a vector:</p><p class="body-text" style="text-align: center; line-height: 0"><span class="tex-holder" style="padding: 8px" data-source-tex="\begin{align*}[NEWLINE][TAB]T \left( \left[\begin{array}{c} x_1 \\ x_2 \end{array}\right] \right) = \left[\begin{array}{cc} a_{11}& a_{12} \\ a_{21}& a_{22} \end{array}\right] \left[\begin{array}{c} x_1 \\ x_2 \end{array}\right].[NEWLINE]\end{align*}">$$\begin{align*}T \left( \left[\begin{array}{c} x_1 \\ x_2 \end{array}\right] \right) = \left[\begin{array}{cc} a_{11}& a_{12} \\ a_{21}& a_{22} \end{array}\right] \left[\begin{array}{c} x_1 \\ x_2 \end{array}\right].\end{align*}$$</span></p><p class="body-text">And so we get to the fundamental result of the section: <strong>linear transformations from <span class="tex-holder inline-math" data-source-tex="\mathbb{R}^n">$\mathbb{R}^n$</span> to <span class="tex-holder inline-math" data-source-tex="\mathbb{R}^m">$\mathbb{R}^m$</span> are just <span class="tex-holder inline-math" data-source-tex="m \times n">$m \times n$</span> matrices</strong>. We knew the reverse &mdash; that matrices were linear maps &mdash; but this says that the other direction is also true, and so we can interchangeably refer to linear transformations and matrices. To represent a linear transformation as a matrix, evaluate it on all of the <span class="tex-holder inline-math" data-source-tex="\vec{e_i}">$\vec{e_i}$</span> (the vectors with a <span class="tex-holder inline-math" data-source-tex="1">$1$</span> in position <span class="tex-holder inline-math" data-source-tex="i">$i$</span> and zeros everywhere else), and place the results as the columns of a matrix.</p><div class="notes-ex notes-environment"><div class="notes-ex-title notes-title">Example: linear transformations as matrices</div><p class="body-text">Let <span class="tex-holder inline-math" data-source-tex="T : \mathbb{R}^3 \to \mathbb{R}^3">$T : \mathbb{R}^3 \to \mathbb{R}^3$</span> be the linear transformation defined by</p><p class="body-text" style="text-align: center; line-height: 0"><span class="tex-holder" style="padding: 8px" data-source-tex="\begin{align*}[NEWLINE][TAB]T\left( \left[\begin{array}{c} a \\ b \\ c \end{array}\right] \right) &= \left[\begin{array}{c} 2a + 3b \\ b + 2a \\ 2c - a \end{array}\right],[NEWLINE]\end{align*}">$$\begin{align*}T\left( \left[\begin{array}{c} a \\ b \\ c \end{array}\right] \right) &= \left[\begin{array}{c} 2a + 3b \\ b + 2a \\ 2c - a \end{array}\right],\end{align*}$$</span></p><p class="body-text">Find the matrix for <span class="tex-holder inline-math" data-source-tex="T">$T$.</span></p><div class="solution"></div><p class="body-text">By evaluating <span class="tex-holder inline-math" data-source-tex="T">$T$</span> on <span class="tex-holder inline-math" data-source-tex="\vec{e_1}">$\vec{e_1}$,</span> <span class="tex-holder inline-math" data-source-tex="\vec{e_2}">$\vec{e_2}$,</span> <span class="tex-holder inline-math" data-source-tex="\vec{e_3}">$\vec{e_3}$,</span> we have</p><p class="body-text" style="text-align: center; line-height: 0"><span class="tex-holder" style="padding: 8px" data-source-tex="\begin{align*}[NEWLINE][TAB]T(\vec{e_1}) &= \left[\begin{array}{c} 2 \\ 2 \\ -1 \end{array}\right]\\[NEWLINE][TAB]T(\vec{e_2}) &= \left[\begin{array}{c} 3 \\ 1 \\ 0 \end{array}\right]\\[NEWLINE][TAB]T(\vec{e_3}) &= \left[\begin{array}{c} 0 \\ 0 \\ 2 \end{array}\right],[NEWLINE]\end{align*}">$$\begin{align*}T(\vec{e_1}) &= \left[\begin{array}{c} 2 \\ 2 \\ -1 \end{array}\right]\\[4px]T(\vec{e_2}) &= \left[\begin{array}{c} 3 \\ 1 \\ 0 \end{array}\right]\\[4px]T(\vec{e_3}) &= \left[\begin{array}{c} 0 \\ 0 \\ 2 \end{array}\right],\end{align*}$$</span></p><p class="body-text">and so the matrix for <span class="tex-holder inline-math" data-source-tex="T">$T$</span> is</p><p class="body-text" style="text-align: center; line-height: 0"><span class="tex-holder" style="padding: 8px" data-source-tex="\begin{align*}[NEWLINE][TAB]A = \left[\begin{array}{ccc} 2& 3& 0 \\ 2& 1& 0 \\ -1& 0& 2 \end{array}\right].[NEWLINE]\end{align*}">$$\begin{align*}A = \left[\begin{array}{ccc} 2& 3& 0 \\ 2& 1& 0 \\ -1& 0& 2 \end{array}\right].\end{align*}$$</span></p><p class="body-text">In other words, <span class="tex-holder inline-math" data-source-tex="T(\vec{v}) = A\vec{v}">$T(\vec{v}) = A\vec{v}$</span> for any vector <span class="tex-holder inline-math" data-source-tex="\vec{v} \in \mathbb{R}^3">$\vec{v} \in \mathbb{R}^3$.</span> This is the core of the idea that matrices are functions that act by multiplication: on the left is the function, and on the right is the matrix multiplication.</p></div><div class="notes-exc notes-environment"><div class="notes-exc-title notes-title">Exercise: linear transformations as matrices</div><p class="body-text">Let <span class="tex-holder inline-math" data-source-tex="S : \mathbb{R}^3 \to \mathbb{R}^2">$S : \mathbb{R}^3 \to \mathbb{R}^2$</span> be a linear transformation defined by</p><p class="body-text" style="text-align: center; line-height: 0"><span class="tex-holder" style="padding: 8px" data-source-tex="\begin{align*}[NEWLINE][TAB]S\left( \left[\begin{array}{c} x \\ y \\ z \end{array}\right] \right) &= \left[\begin{array}{c} x + z \\ 3x - 2y \end{array}\right].[NEWLINE]\end{align*}">$$\begin{align*}S\left( \left[\begin{array}{c} x \\ y \\ z \end{array}\right] \right) &= \left[\begin{array}{c} x + z \\ 3x - 2y \end{array}\right].\end{align*}$$</span></p><p class="body-text">Find the matrix <span class="tex-holder inline-math" data-source-tex="B">$B$</span> for <span class="tex-holder inline-math" data-source-tex="S">$S$,</span> and then verify that the matrix for the composition <span class="tex-holder inline-math" data-source-tex="S \circ T">$S \circ T$</span> is <span class="tex-holder inline-math" data-source-tex="BA">$BA$.</span></p></div></section><h2 class="section-text">Properties of Transformations</h2><section><p class="body-text">With the foundation of matrices, inverses, linear transformations, and linear independence, we&#x2019;re ready to tie everything we&#x2019;ve learned together. We&#x2019;ll begin by defining two properties that a linear transformation can have, and we&#x2019;ll soon see how they relate to the ones we&#x2019;ve already seen.</p><div class="notes-def notes-environment"><div class="notes-def-title notes-title">Definition: one-to-one and onto</div><p class="body-text">A function <span class="tex-holder inline-math" data-source-tex="f : \mathbb{R}^n \to \mathbb{R}^m">$f : \mathbb{R}^n \to \mathbb{R}^m$</span> is <strong>one-to-one</strong> (or <strong>injective</strong>) if <span class="tex-holder inline-math" data-source-tex="f(\vec{v}) \neq f(\vec{w})">$f(\vec{v}) \neq f(\vec{w})$</span> whenever <span class="tex-holder inline-math" data-source-tex="\vec{v} \neq \vec{w}">$\vec{v} \neq \vec{w}$.</span> It&#x2019;s <strong>onto</strong> (or <strong>surjective</strong>) if every vector <span class="tex-holder inline-math" data-source-tex="\vec{u} \in \mathbb{R}^m">$\vec{u} \in \mathbb{R}^m$</span> satisfies <span class="tex-holder inline-math" data-source-tex="\vec{u} = f(\vec{v})">$\vec{u} = f(\vec{v})$</span> for some vector <span class="tex-holder inline-math" data-source-tex="\vec{v} \in \mathbb{R}^n">$\vec{v} \in \mathbb{R}^n$.</span></p></div><p class="body-text">In simple terms, one-to-one functions are those that pass the horizontal line test, and onto ones are those whose image (i.e. range) is equal to their codomain.</p><p class="body-text">This first definition of one-to-one is unfortunately a little too clunky to work with directly most of the time. Instead, we&#x2019;ll use an equivalent one that&#x2019;s quite a bit more streamlined.</p><div class="notes-prop notes-environment"><div class="notes-prop-title notes-title">Proposition: an equivalent one-to-one definition</div><p class="body-text">A linear transformation <span class="tex-holder inline-math" data-source-tex="T : \mathbb{R}^n \to \mathbb{R}^m">$T : \mathbb{R}^n \to \mathbb{R}^m$</span> is one-to-one exactly when the only vector <span class="tex-holder inline-math" data-source-tex="\vec{v} \in \mathbb{R}^n">$\vec{v} \in \mathbb{R}^n$</span> for which <span class="tex-holder inline-math" data-source-tex="T(\vec{v}) = \vec{0}">$T(\vec{v}) = \vec{0}$</span> is <span class="tex-holder inline-math" data-source-tex="\vec{v} = \vec{0}">$\vec{v} = \vec{0}$.</span></p></div><div class="notes-pf notes-environment"><div class="notes-pf-title notes-title">Proof</div><p class="body-text">Let&#x2019;s very briefly sketch the reasoning behind this proposition. First of all, if <span class="tex-holder inline-math" data-source-tex="T">$T$</span> sends a vector <span class="tex-holder inline-math" data-source-tex="\vec{v} \neq \vec{0}">$\vec{v} \neq \vec{0}$</span> to <span class="tex-holder inline-math" data-source-tex="\vec{0}">$\vec{0}$,</span> then <span class="tex-holder inline-math" data-source-tex="T(\vec{v}) = \vec{0} = T(\vec{0})">$T(\vec{v}) = \vec{0} = T(\vec{0})$,</span> so <span class="tex-holder inline-math" data-source-tex="T">$T$</span> isn&#x2019;t one-to-one. On the other hand, if the only vector <span class="tex-holder inline-math" data-source-tex="T">$T$</span> sends to <span class="tex-holder inline-math" data-source-tex="\vec{0}">$\vec{0}$</span> is <span class="tex-holder inline-math" data-source-tex="\vec{0}">$\vec{0}$,</span> then whenever we have <span class="tex-holder inline-math" data-source-tex="T(\vec{v}) = T(\vec{w})">$T(\vec{v}) = T(\vec{w})$,</span> we can rearrange it to get</p><p class="body-text" style="text-align: center; line-height: 0"><span class="tex-holder" style="padding: 8px" data-source-tex="$$[NEWLINE][TAB]T(\vec{w}) - T(\vec{w}) = T(\vec{v} - \vec{w}) = \vec{0},[NEWLINE]$$">$$\begin{align*}T(\vec{w}) - T(\vec{w}) = T(\vec{v} - \vec{w}) = \vec{0},\end{align*}$$</span></p><p class="body-text">And under the assumption, that means <span class="tex-holder inline-math" data-source-tex="\vec{v} - \vec{w} = \vec{0}">$\vec{v} - \vec{w} = \vec{0}$,</span> so <span class="tex-holder inline-math" data-source-tex="\vec{v} = \vec{w}">$\vec{v} = \vec{w}$,</span> meaning <span class="tex-holder inline-math" data-source-tex="T">$T$</span> is one-to-one.</p></div><p class="body-text">It&#x2019;s important to note that this alternate definition works <em>only</em> with linear transformations, not functions in general. For example, <span class="tex-holder inline-math" data-source-tex="f(x) = x^2">$f(x) = x^2$</span> isn&#x2019;t one-to-one, since <span class="tex-holder inline-math" data-source-tex="f(1) = f(-1)">$f(1) = f(-1)$,</span> but the only <span class="tex-holder inline-math" data-source-tex="x">$x$</span> with <span class="tex-holder inline-math" data-source-tex="f(x) = 0">$f(x) = 0$</span> is <span class="tex-holder inline-math" data-source-tex="x = 0">$x = 0$.</span></p><p class="body-text">Similarly, we&#x2019;ll want to use a different definition of onto when we&#x2019;re actually working with transformations. Recall that applying a linear transformation to a vector results in taking a linear combination of the columns of the linear transformation&#x2019;s matrix, where the coefficients are given by the vector (this is just restating matrix-vector multiplication). For example, the transformation <span class="tex-holder inline-math" data-source-tex="T : \mathbb{R}^2 \to \mathbb{R}^3">$T : \mathbb{R}^2 \to \mathbb{R}^3$</span> defined by</p><p class="body-text" style="text-align: center; line-height: 0"><span class="tex-holder" style="padding: 8px" data-source-tex="$$[NEWLINE][TAB]T\left( \left[\begin{array}{c} x \\ y \end{array}\right] \right) = \left[\begin{array}{c} 2x + y \\ -y \\ 3x + 4y \end{array}\right][NEWLINE]$$">$$\begin{align*}T\left( \left[\begin{array}{c} x \\ y \end{array}\right] \right) = \left[\begin{array}{c} 2x + y \\ -y \\ 3x + 4y \end{array}\right]\end{align*}$$</span></p><p class="body-text">corresponds to the matrix</p><p class="body-text" style="text-align: center; line-height: 0"><span class="tex-holder" style="padding: 8px" data-source-tex="\begin{align*}[NEWLINE][TAB]\left[\begin{array}{cc} 2& 1 \\ 0& -1 \\ 3& 4\end{array}\right][NEWLINE]\end{align*}">$$\begin{align*}\left[\begin{array}{cc} 2& 1 \\ 0& -1 \\ 3& 4\end{array}\right]\end{align*}$$</span></p><p class="body-text">and applying it to a vector results in</p><p class="body-text" style="text-align: center; line-height: 0"><span class="tex-holder" style="padding: 8px" data-source-tex="\begin{align*}[NEWLINE][TAB]\left[\begin{array}{cc} 2& 1 \\ 0& -1 \\ 3& 4\end{array}\right] \left[\begin{array}{c} x \\ y \end{array}\right] = \left[\begin{array}{c} 2 \\ 0 \\ 3 \end{array}\right]x + \left[\begin{array}{c} 1 \\ -1 \\ 4 \end{array}\right]y.[NEWLINE]\end{align*}">$$\begin{align*}\left[\begin{array}{cc} 2& 1 \\ 0& -1 \\ 3& 4\end{array}\right] \left[\begin{array}{c} x \\ y \end{array}\right] = \left[\begin{array}{c} 2 \\ 0 \\ 3 \end{array}\right]x + \left[\begin{array}{c} 1 \\ -1 \\ 4 \end{array}\right]y.\end{align*}$$</span></p><p class="body-text">Since we can plug in whatever we like for <span class="tex-holder inline-math" data-source-tex="x">$x$</span> and <span class="tex-holder inline-math" data-source-tex="y">$y$,</span> the image of <span class="tex-holder inline-math" data-source-tex="T">$T$</span> &mdash; the set of outputs that actually occur &mdash; is the <em>span of the columns of the matrix corresponding to <span class="tex-holder inline-math" data-source-tex="T">$T$</em>.</span> That&#x2019;s absolutely a mouthful, so let&#x2019;s give it a more concise name.</p><div class="notes-def notes-environment"><div class="notes-def-title notes-title">Definition: column space</div><p class="body-text">Let <span class="tex-holder inline-math" data-source-tex="T">$T$</span> be a linear transformation. The <strong>column space</strong> of <span class="tex-holder inline-math" data-source-tex="T">$T$</span> is the span of the columns of the matrix corresponding to <span class="tex-holder inline-math" data-source-tex="T">$T$.</span> The column space of <span class="tex-holder inline-math" data-source-tex="T">$T$</span> is equal to <span class="tex-holder inline-math" data-source-tex="\operatorname{image} T">$\operatorname{image} T$,</span> so we don&#x2019;t need extra notation to distinguish it.</p></div><p class="body-text">Let&#x2019;s finally bring it all together. For a linear transformation <span class="tex-holder inline-math" data-source-tex="T : \mathbb{R}^n \to \mathbb{R}^m">$T : \mathbb{R}^n \to \mathbb{R}^m$</span> to be onto &mdash; that is, for its column space to be equal to <span class="tex-holder inline-math" data-source-tex="\mathbb{R}^m">$\mathbb{R}^m$</span> &mdash; we need the columns of the matrix for <span class="tex-holder inline-math" data-source-tex="T">$T$</span> to have at least <span class="tex-holder inline-math" data-source-tex="m">$m$</span> linearly independent vectors among them. On the other hand, for <span class="tex-holder inline-math" data-source-tex="T">$T$</span> to be one-to-one, we need <em>all</em> the columns to be linearly independent &mdash; if there&#x2019;s any linear dependence, then two different inputs will get sent to the same output. It&#x2019;s tempting to say that being one-to-one is a stronger condition than being onto, but this actually isn&#x2019;t always the case, as we&#x2019;ll shortly see. For now, though, we can state the result that will let us properly evaluate individual transformations.</p><div class="notes-thm notes-environment"><div class="notes-thm-title notes-title">Theorem: criteria for one-to-one and onto</div><p class="body-text">Let <span class="tex-holder inline-math" data-source-tex="T : \mathbb{R}^n \to \mathbb{R}^m">$T : \mathbb{R}^n \to \mathbb{R}^m$</span> be a linear transformation and let <span class="tex-holder inline-math" data-source-tex="A">$A$</span> be the <span class="tex-holder inline-math" data-source-tex="m \times n">$m \times n$</span> matrix corresponding to it. Then <span class="tex-holder inline-math" data-source-tex="T">$T$</span> is one-to-one exactly when all the columns of <span class="tex-holder inline-math" data-source-tex="A">$A$</span> are linearly independent, and <span class="tex-holder inline-math" data-source-tex="T">$T$</span> is onto exactly when there are at least <span class="tex-holder inline-math" data-source-tex="m">$m$</span> linearly independent columns of <span class="tex-holder inline-math" data-source-tex="A">$A$.</span></p></div><p class="body-text">To check how many vectors in a set (e.g. the columns of a matrix) are linearly independent, the simplest method is to place them all as <em>rows</em> in a matrix and reduce it. That&#x2019;s because row operations replace rows with linear combinations of other rows, with the goal of making them zero if possible. When we&#x2019;re done reducing, the number of nonzero rows left is the number of linearly independent vectors in the set we started with.</p><div class="notes-ex notes-environment"><div class="notes-ex-title notes-title">Example: one-to-one and onto</div><p class="body-text">Let <span class="tex-holder inline-math" data-source-tex="T : \mathbb{R}^3 \to \mathbb{R}^3">$T : \mathbb{R}^3 \to \mathbb{R}^3$</span> be defined by</p><p class="body-text" style="text-align: center; line-height: 0"><span class="tex-holder" style="padding: 8px" data-source-tex="$$[NEWLINE][TAB]T\left( \left[\begin{array}{c} x \\ y \\ z \end{array}\right] \right) = \left[\begin{array}{c} 2x + 3y + 5z \\ 3x + 4y + 7z \\ x - 2y - z \end{array}\right].[NEWLINE]$$">$$\begin{align*}T\left( \left[\begin{array}{c} x \\ y \\ z \end{array}\right] \right) = \left[\begin{array}{c} 2x + 3y + 5z \\ 3x + 4y + 7z \\ x - 2y - z \end{array}\right].\end{align*}$$</span></p><p class="body-text">Is <span class="tex-holder inline-math" data-source-tex="T">$T$</span> one-to-one? Is it onto?</p><div class="solution"></div><p class="body-text">By the previous theorem, we first want to express <span class="tex-holder inline-math" data-source-tex="T">$T$</span> as a matrix: it corresponds to</p><p class="body-text" style="text-align: center; line-height: 0"><span class="tex-holder" style="padding: 8px" data-source-tex="\begin{align*}[NEWLINE][TAB]A = \left[\begin{array}{ccc} 2& 3& 5 \\ 3& 4& 7 \\ 1& -2& -1 \end{array}\right],[NEWLINE]\end{align*}">$$\begin{align*}A = \left[\begin{array}{ccc} 2& 3& 5 \\ 3& 4& 7 \\ 1& -2& -1 \end{array}\right],\end{align*}$$</span></p><p class="body-text">so we want to row-reduce the matrix whose rows are the columns of <span class="tex-holder inline-math" data-source-tex="A">$A$.</span></p><p class="body-text" style="text-align: center; line-height: 0"><span class="tex-holder" style="padding: 8px" data-source-tex="\begin{align*}[NEWLINE][TAB]\left[\begin{array}{ccc} 2& 3& 1 \\ 3& 4& -2 \\ 5& 7& -1 \end{array}\right] &\\[NEWLINE][TAB]\left[\begin{array}{ccc} 2& 3& 1 \\ 6& 8& -4 \\ 10& 14& -2 \end{array}\right] & \qquad \begin{array}{l} \vec{r_2} \to 2\vec{r_2} \\ \vec{r_2} \to 2\vec{r_2} \end{array}\\[NEWLINE][TAB]\left[\begin{array}{ccc} 2& 3& 1 \\ 0& -1& -7 \\ 0& -1& -7 \end{array}\right] & \qquad \begin{array}{l} \vec{r_2} \to \vec{r_2} - 3\vec{r_1} \\ \vec{r_3} \to \vec{r_3} - 5 \vec{r_1} \end{array}\\[NEWLINE][TAB]\left[\begin{array}{ccc} 2& 3& 1 \\ 0& -1& -7 \\ 0& 0& 0 \end{array}\right] & \qquad \vec{r_3} \to \vec{r_3} - \vec{r_2}\\[NEWLINE][TAB]\left[\begin{array}{ccc} 2& 0& 20 \\ 0& -1& -7 \\ 0& 0& 0 \end{array}\right] & \qquad \vec{r_1} \to \vec{r_1} + 3\vec{r_2}\\[NEWLINE][TAB]\left[\begin{array}{ccc} 1& 0& 10 \\ 0& 1& 7 \\ 0& 0& 0 \end{array}\right] & \qquad \begin{array}{l} \vec{r_1} \to \frac{1}{2}\vec{r_1} \\ \vec{r_2} \to -\vec{r_2} \end{array}[NEWLINE]\end{align*}">$$\begin{align*}\left[\begin{array}{ccc} 2& 3& 1 \\ 3& 4& -2 \\ 5& 7& -1 \end{array}\right] &\\[4px]\left[\begin{array}{ccc} 2& 3& 1 \\ 6& 8& -4 \\ 10& 14& -2 \end{array}\right] & \qquad \begin{array}{l} \vec{r_2} \to 2\vec{r_2} \\ \vec{r_2} \to 2\vec{r_2} \end{array}\\[4px]\left[\begin{array}{ccc} 2& 3& 1 \\ 0& -1& -7 \\ 0& -1& -7 \end{array}\right] & \qquad \begin{array}{l} \vec{r_2} \to \vec{r_2} - 3\vec{r_1} \\ \vec{r_3} \to \vec{r_3} - 5 \vec{r_1} \end{array}\\[4px]\left[\begin{array}{ccc} 2& 3& 1 \\ 0& -1& -7 \\ 0& 0& 0 \end{array}\right] & \qquad \vec{r_3} \to \vec{r_3} - \vec{r_2}\\[4px]\left[\begin{array}{ccc} 2& 0& 20 \\ 0& -1& -7 \\ 0& 0& 0 \end{array}\right] & \qquad \vec{r_1} \to \vec{r_1} + 3\vec{r_2}\\[4px]\left[\begin{array}{ccc} 1& 0& 10 \\ 0& 1& 7 \\ 0& 0& 0 \end{array}\right] & \qquad \begin{array}{l} \vec{r_1} \to \frac{1}{2}\vec{r_1} \\ \vec{r_2} \to -\vec{r_2} \end{array}\end{align*}$$</span></p><p class="body-text">In the end, we have two linearly independent rows, so <span class="tex-holder inline-math" data-source-tex="A">$A$</span> has only two independent columns. Since not all the columns were independent, <span class="tex-holder inline-math" data-source-tex="T">$T$</span> isn&#x2019;t one-to-one, and since there weren&#x2019;t at least three linearly independent columns, <span class="tex-holder inline-math" data-source-tex="T">$T$</span> isn&#x2019;t onto. That sentence certainly seems a bit redundant when we write it out, and we&#x2019;ll have more to say on the subject momentarily.</p></div><div class="notes-exc notes-environment"><div class="notes-exc-title notes-title">Exercise: one-to-one and onto</div><p class="body-text">Let <span class="tex-holder inline-math" data-source-tex="S : \mathbb{R}^3 \to \mathbb{R}^2">$S : \mathbb{R}^3 \to \mathbb{R}^2$</span> be defined by</p><p class="body-text" style="text-align: center; line-height: 0"><span class="tex-holder" style="padding: 8px" data-source-tex="$$[NEWLINE][TAB]S\left( \left[\begin{array}{c} x \\ y \\ z \end{array}\right] \right) = \left[\begin{array}{c} x + y - z \\ 2x + y - 3z \end{array}\right].[NEWLINE]$$">$$\begin{align*}S\left( \left[\begin{array}{c} x \\ y \\ z \end{array}\right] \right) = \left[\begin{array}{c} x + y - z \\ 2x + y - 3z \end{array}\right].\end{align*}$$</span></p><p class="body-text">Is <span class="tex-holder inline-math" data-source-tex="S">$S$</span> one-to-one? Is it onto?</p></div></section><h2 class="section-text">Invertibility</h2><section><p class="body-text">Let&#x2019;s consider, for yet another time, a linear transformation <span class="tex-holder inline-math" data-source-tex="T : \mathbb{R}^n \to \mathbb{R}^m">$T : \mathbb{R}^n \to \mathbb{R}^m$.</span> If <span class="tex-holder inline-math" data-source-tex="n > m">$n > m$,</span> then there are more columns than rows in the matrix corresponding to <span class="tex-holder inline-math" data-source-tex="T">$T$,</span> and so the columns can&#x2019;t all possibly be linearly independent. That&#x2019;s because when we place them as rows in an <span class="tex-holder inline-math" data-source-tex="n \times m">$n \times m$</span> matrix and row-reduce it, the best that the process could go is if none of the first <span class="tex-holder inline-math" data-source-tex="m">$m$</span> reduce to rows of all zeros &mdash; but then we could use those reduced rows to clear all of the others. For example, consider the matrix</p><p class="body-text" style="text-align: center; line-height: 0"><span class="tex-holder" style="padding: 8px" data-source-tex="\begin{align*}[NEWLINE][TAB]A = \left[\begin{array}{ccc} 1& 3& 5 \\ -1& 4& 2 \end{array}\right].[NEWLINE]\end{align*}">$$\begin{align*}A = \left[\begin{array}{ccc} 1& 3& 5 \\ -1& 4& 2 \end{array}\right].\end{align*}$$</span></p><p class="body-text">Placing the rows of <span class="tex-holder inline-math" data-source-tex="A">$A$</span> as columns in a new matrix and partially row-reducing, we get</p><p class="body-text" style="text-align: center; line-height: 0"><span class="tex-holder" style="padding: 8px" data-source-tex="\begin{align*}[NEWLINE][TAB]\left[\begin{array}{cc} 1& 1 \\ 3& 4 \\ 5& 2 \end{array}\right] & \\[NEWLINE][TAB]\left[\begin{array}{cc} 1& 1 \\ 0& 1 \\ 5& 2 \end{array}\right] & \qquad \vec{r_2} \ -\!\!= 3\vec{r_1}.[NEWLINE]\end{align*}">$$\begin{align*}\left[\begin{array}{cc} 1& 1 \\ 3& 4 \\ 5& 2 \end{array}\right] & \\[4px]\left[\begin{array}{cc} 1& 1 \\ 0& 1 \\ 5& 2 \end{array}\right] & \qquad \vec{r_2} \ -\!\!= 3\vec{r_1}.\end{align*}$$</span></p><p class="body-text">Since neither of the first two rows is all zero, we&#x2019;re going to be able to reduce the third row to zero no matter what its entries are. Geometrically, if we already have two linearly independent vectors in <span class="tex-holder inline-math" data-source-tex="\mathbb{R}^2">$\mathbb{R}^2$,</span> there&#x2019;s no third vector in <span class="tex-holder inline-math" data-source-tex="\mathbb{R}^2">$\mathbb{R}^2$</span> that&#x2019;s linearly independent with them both.</p><p class="body-text">On the other hand, if <span class="tex-holder inline-math" data-source-tex="n < m">$n < m$,</span> then there are more rows than columns. This case is a lot simpler: for <span class="tex-holder inline-math" data-source-tex="T">$T$</span> to be onto, there need to be at least <span class="tex-holder inline-math" data-source-tex="m">$m$</span> linearly independent columns, but there are only <span class="tex-holder inline-math" data-source-tex="n">$n$</span> columns at all, linearly independent or not. We can sum up our findings in far fewer words:</p><div class="notes-prop notes-environment"><div class="notes-prop-title notes-title">Proposition: one-to-one and/or onto rectangular matrices</div><p class="body-text">Let <span class="tex-holder inline-math" data-source-tex="T : \mathbb{R}^n \to \mathbb{R}^m">$T : \mathbb{R}^n \to \mathbb{R}^m$</span> be a linear transformation. If <span class="tex-holder inline-math" data-source-tex="n > m">$n > m$,</span> then <span class="tex-holder inline-math" data-source-tex="T">$T$</span> can&#x2019;t be one-to-one. If <span class="tex-holder inline-math" data-source-tex="n < m">$n < m$,</span> then <span class="tex-holder inline-math" data-source-tex="T">$T$</span> can&#x2019;t be onto.</p></div><p class="body-text">Geometrically, it&#x2019;s helpful to think of two cases here: first, when <span class="tex-holder inline-math" data-source-tex="n = 2">$n = 2$</span> and <span class="tex-holder inline-math" data-source-tex="m = 1">$m = 1$,</span> we&#x2019;re squishing all of <span class="tex-holder inline-math" data-source-tex="\mathbb{R}^2">$\mathbb{R}^2$</span> down onto <span class="tex-holder inline-math" data-source-tex="\mathbb{R}^1">$\mathbb{R}^1$,</span> which is effectively mapping the <span class="tex-holder inline-math" data-source-tex="xy">$xy$-plane</span> onto the <span class="tex-holder inline-math" data-source-tex="x">$x$-axis.</span> There&#x2019;s just no way to do that in a nice (i.e. linear) fashion without sending many inputs to one output. On the other hand, when <span class="tex-holder inline-math" data-source-tex="n = 1">$n = 1$</span> and <span class="tex-holder inline-math" data-source-tex="m = 2">$m = 2$,</span> we&#x2019;re doing the reverse: mapping the <span class="tex-holder inline-math" data-source-tex="x">$x$-axis</span> into the <span class="tex-holder inline-math" data-source-tex="xy">$xy$-plane.</span> There&#x2019;s no nice way for that map to fill up all of the plane, which is exactly what would need to happen for it to be onto.</p><p class="body-text">When we have a one-to-one and onto linear transformation <span class="tex-holder inline-math" data-source-tex="T : \mathbb{R}^n \to \mathbb{R}^m">$T : \mathbb{R}^n \to \mathbb{R}^m$,</span> then we now know that <span class="tex-holder inline-math" data-source-tex="m = n">$m = n$</span> &mdash; otherwise, one of the two would be impossible. That means the matrix for <span class="tex-holder inline-math" data-source-tex="T">$T$</span> is square, and the two conditions now say exactly the same thing: <span class="tex-holder inline-math" data-source-tex="T">$T$</span> being one-to-one means it has all <span class="tex-holder inline-math" data-source-tex="n">$n$</span> of its columns linearly independent, and onto means it has at least <span class="tex-holder inline-math" data-source-tex="n">$n$</span> of its columns linearly independent. And in fact, both being one-to-one and being onto are equivalent to a property we&#x2019;re already familiar with:</p><div class="notes-thm notes-environment"><div class="notes-thm-title notes-title">Theorem: invertibility</div><p class="body-text">Let <span class="tex-holder inline-math" data-source-tex="T : \mathbb{R}^n \to \mathbb{R}^n">$T : \mathbb{R}^n \to \mathbb{R}^n$</span> be a linear transformation whose domain and codomain are the same. Then all of the following statements are equivalent:</p><p class="body-text numbered-list-item">1. <span class="tex-holder inline-math" data-source-tex="T">$T$</span> is one-to-one.</p><p class="body-text numbered-list-item">2. <span class="tex-holder inline-math" data-source-tex="T">$T$</span> is onto.</p><p class="body-text numbered-list-item">3. <span class="tex-holder inline-math" data-source-tex="T">$T$</span> is invertible.</p></div><p class="body-text">Our transformation in the previous example isn&#x2019;t invertible by this theorem, which means both that there is no inverse linear transformation and that the corresponding matrix isn&#x2019;t invertible. In fact, we didn&#x2019;t even need to ask whether it was onto after concluding it was one-to-one: since the matrix was square, the two properties are one and the same.</p><p class="body-text">At this point, we&#x2019;re finished with the material in the section, but I think it&#x2019;s worth taking a minute to summarize where we are in regard to linear transformations, matrices, and the interplay between them. There are a lot of terms and ideas to digest, and a quick list organizing many of them should help. For all the items in the list, we let <span class="tex-holder inline-math" data-source-tex="T : \mathbb{R}^n \to \mathbb{R}^m">$T : \mathbb{R}^n \to \mathbb{R}^m$</span> be a linear transformation and <span class="tex-holder inline-math" data-source-tex="A">$A$</span> its corresponding matrix.</p><p class="body-text"><span style="width: 32px"></span><strong>&#8226;</strong> Evaluation: we evaluate <span class="tex-holder inline-math" data-source-tex="T(\vec{v})">$T(\vec{v})$</span> by plugging the entries of <span class="tex-holder inline-math" data-source-tex="\vec{v}">$\vec{v}$</span> into a formula for <span class="tex-holder inline-math" data-source-tex="T">$T$,</span> just like a one-variable function <span class="tex-holder inline-math" data-source-tex="f(x)">$f(x)$.</span> We evaluate a matrix on a vector by the matrix-vector multiplication <span class="tex-holder inline-math" data-source-tex="A\vec{v}">$A\vec{v}$.</span></p><p class="body-text"><span style="width: 32px"></span><strong>&#8226;</strong> Composition: we compose <span class="tex-holder inline-math" data-source-tex="T">$T$</span> with another linear map <span class="tex-holder inline-math" data-source-tex="S: \mathbb{R}^m \to \mathbb{R}^k">$S: \mathbb{R}^m \to \mathbb{R}^k$</span> to form the map <span class="tex-holder inline-math" data-source-tex="T \circ S : \mathbb{R}^n \to \mathbb{R}^k">$T \circ S : \mathbb{R}^n \to \mathbb{R}^k$</span> by plugging the formula for the output of <span class="tex-holder inline-math" data-source-tex="S">$S$</span> as the input to the formula for <span class="tex-holder inline-math" data-source-tex="T">$T$.</span> We compose <span class="tex-holder inline-math" data-source-tex="A">$A$</span> with an <span class="tex-holder inline-math" data-source-tex="m \times k">$m \times k$</span> matrix <span class="tex-holder inline-math" data-source-tex="B">$B$</span> to form <span class="tex-holder inline-math" data-source-tex="AB">$AB$</span> by matrix multiplication.</p><p class="body-text"><span style="width: 32px"></span><strong>&#8226;</strong> One-to-one: <span class="tex-holder inline-math" data-source-tex="T">$T$</span> is one-to-one if <span class="tex-holder inline-math" data-source-tex="T(\vec{v}) \neq T(\vec{w})">$T(\vec{v}) \neq T(\vec{w})$</span> for <span class="tex-holder inline-math" data-source-tex="\vec{v} \neq \vec{w}">$\vec{v} \neq \vec{w}$,</span> if <span class="tex-holder inline-math" data-source-tex="T(\vec{v}) \neq T(\vec{0})">$T(\vec{v}) \neq T(\vec{0})$</span> for <span class="tex-holder inline-math" data-source-tex="\vec{v} \neq \vec{0}">$\vec{v} \neq \vec{0}$,</span> or if all of the columns of <span class="tex-holder inline-math" data-source-tex="A">$A$</span> are linearly independent.</p><p class="body-text"><span style="width: 32px"></span><strong>&#8226;</strong> Onto: <span class="tex-holder inline-math" data-source-tex="T">$T$</span> is onto if for any vector <span class="tex-holder inline-math" data-source-tex="\vec{w} \in \mathbb{R}^m">$\vec{w} \in \mathbb{R}^m$,</span> there is a vector <span class="tex-holder inline-math" data-source-tex="\vec{v} \in \mathbb{R}^n">$\vec{v} \in \mathbb{R}^n$</span> with <span class="tex-holder inline-math" data-source-tex="T(\vec{v} = \vec{w})">$T(\vec{v} = \vec{w})$,</span> or if there are at least <span class="tex-holder inline-math" data-source-tex="m">$m$</span> linearly independent columns of <span class="tex-holder inline-math" data-source-tex="A">$A$.</span></p><p class="body-text"><span style="width: 32px"></span><strong>&#8226;</strong> Invertibility: <span class="tex-holder inline-math" data-source-tex="T">$T$</span> is invertible if its domain and codomain are equal (so <span class="tex-holder inline-math" data-source-tex="m = n">$m = n$),</span> and it is one-to-one and onto (checking either one of those suffices to determine both). Alternatively, <span class="tex-holder inline-math" data-source-tex="T">$T$</span> is invertible if <span class="tex-holder inline-math" data-source-tex="A">$A$</span> is invertible, meaning it row-reduces to the identity matrix.</p><p class="body-text"><span style="width: 32px"></span><strong>&#8226;</strong> Inversion: we don&#x2019;t invert transformations directly with their formulas, only with their matrices. With a matrix <span class="tex-holder inline-math" data-source-tex="A">$A$,</span> we invert it by augmenting with <span class="tex-holder inline-math" data-source-tex="I">$I$</span> and row-reducing.</p><p class="body-text">We&#x2019;re getting some hints that the bulk of the subject lies with square matrices: they&#x2019;re the only ones that can be invertible, and being one-to-one and onto are identical conditions. And as we&#x2019;ll see in the next section, the next big object we&#x2019;ll want to develop depends on the matrices it takes in being square.</p><div class="text-buttons nav-buttons"><div class="focus-on-child" tabindex="1"><button class="text-button linked-text-button nav-button previous-nav-button" type="button" tabindex="-1">Previous</button></div><div class="focus-on-child" tabindex="1"><button class="text-button linked-text-button nav-button home-nav-button" type="button" tabindex="-1">Home</button></div><div class="focus-on-child" tabindex="1"><button class="text-button linked-text-button nav-button next-nav-button" type="button" tabindex="-1">Next</button></div></div></section></main>