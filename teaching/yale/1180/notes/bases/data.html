<header><div id="logo"><a href="/home" tabindex="-1"><img src="/graphics/general-icons/logo.webp" alt="Logo" tabindex="1"></img></a></div><div style="height: 20px"></div><h1 class="heading-text">Section 12: Linear Independence and Bases</h1></header><main><section><div class="text-buttons nav-buttons"><div class="focus-on-child" tabindex="1"><button class="text-button linked-text-button nav-button previous-nav-button" type="button" tabindex="-1">Previous</button></div><div class="focus-on-child" tabindex="1"><button class="text-button linked-text-button nav-button home-nav-button" type="button" tabindex="-1">Home</button></div><div class="focus-on-child" tabindex="1"><button class="text-button linked-text-button nav-button next-nav-button" type="button" tabindex="-1">Next</button></div></div><p class="body-text">With row reduction in hand, we can begin to examine more properties of matrices and vectors. In the context of linear algebra, our primary use for vectors is to represent systems of equations with many equations and unknowns, and a critical feature of those systems is that they don&#x2019;t always have just one solution. For example, let&#x2019;s look at the system</p><p class="body-text" style="text-align: center; line-height: 0"><span class="tex-holder" style="padding: 8px" data-source-tex="\begin{align*}[NEWLINE][TAB]x_1 - x_2 &= 3\\[NEWLINE][TAB]-2x_1 + 2x_2 &= -6.[NEWLINE]\end{align*}">$$\begin{align*}x_1 - x_2 &= 3\\[4px]-2x_1 + 2x_2 &= -6.\end{align*}$$</span></p><p class="body-text">To solve this system, we&#x2019;ll put it into a matrix and row reduce it.</p><p class="body-text" style="text-align: center; line-height: 0"><span class="tex-holder" style="padding: 8px" data-source-tex="\begin{align*}[NEWLINE][TAB]\left[\begin{array}{cc|c} 1& -1 & 3 \\ -2& 2 & -6 \end{array}\right] & \\[NEWLINE][TAB]\left[\begin{array}{cc|c} 1& -1 & 3 \\ 0& 0 & 0 \end{array}\right] & \qquad \vec{r_2} \to \vec{r_2} + 2\vec{r_1}.[NEWLINE]\end{align*}">$$\begin{align*}\left[\begin{array}{cc|c} 1& -1 & 3 \\ -2& 2 & -6 \end{array}\right] & \\[4px]\left[\begin{array}{cc|c} 1& -1 & 3 \\ 0& 0 & 0 \end{array}\right] & \qquad \vec{r_2} \to \vec{r_2} + 2\vec{r_1}.\end{align*}$$</span></p><p class="body-text">The system is now in reduced row echelon form: that row of all zeros prevents us from clearing the <span class="tex-holder inline-math" data-source-tex="-1">$-1$</span> in the first row. The best we can do is convert this back to a system of equations, which gives us <span class="tex-holder inline-math" data-source-tex="x_1 - x_2 = 3">$x_1 - x_2 = 3$.</span> The second equation is just <span class="tex-holder inline-math" data-source-tex="0 = 0">$0 = 0$,</span> which is useless to us since it&#x2019;s always true and doesn&#x2019;t contain any variables.</p><p class="body-text">When we have more unknowns than equations like this, we get a solution involving <strong>free parameters</strong>. If <span class="tex-holder inline-math" data-source-tex="x_2 = t">$x_2 = t$</span> for <em>any</em> value of <span class="tex-holder inline-math" data-source-tex="t">$t$,</span> then <span class="tex-holder inline-math" data-source-tex="x_1 = 3 + t">$x_1 = 3 + t$</span> is a solution. We can write a vector solution as</p><p class="body-text" style="text-align: center; line-height: 0"><span class="tex-holder" style="padding: 8px" data-source-tex="$$[NEWLINE][TAB]\vec{x} = \left[\begin{array}{c} 3 + t \\ t \end{array}\right].[NEWLINE]$$">$$\begin{align*}\vec{x} = \left[\begin{array}{c} 3 + t \\ t \end{array}\right].\end{align*}$$</span></p><p class="body-text">Generally speaking, encountering rows of all zeros while row reducing a square matrix means that we&#x2019;ll have one or more free parameters in our solution. But it sure seems like we could identify the problem upstream: those first two equations weren&#x2019;t very different from one another. Since the second equation was <span class="tex-holder inline-math" data-source-tex="-2">$-2$</span> times the first, it didn&#x2019;t contribute any new information to the system. Put another way, <span class="tex-holder inline-math" data-source-tex="-2">$-2$</span> times the first row plus <span class="tex-holder inline-math" data-source-tex="1">$1$</span> times the second row equals the zero vector, and it&#x2019;s this situation &mdash; and generalizations of it when there are more than two vectors &mdash; that&#x2019;s exactly what we&#x2019;ll want to understand.</p><div class="notes-def notes-environment"><div class="notes-def-title notes-title">Definition: linear combination</div><p class="body-text">Let <span class="tex-holder inline-math" data-source-tex="\vec{v_1}, ..., \vec{v_k} \in \mathbb{R}^n">$\vec{v_1}, ..., \vec{v_k} \in \mathbb{R}^n$.</span> A <strong>linear combination</strong> of the <span class="tex-holder inline-math" data-source-tex="\vec{v_i}">$\vec{v_i}$</span> is a vector of the form</p><p class="body-text" style="text-align: center; line-height: 0"><span class="tex-holder" style="padding: 8px" data-source-tex="$$[NEWLINE][TAB]c_1\vec{v_1} + \cdots + c_k\vec{v_k}[NEWLINE]$$">$$\begin{align*}c_1\vec{v_1} + \cdots + c_k\vec{v_k}\end{align*}$$</span></p><p class="body-text">for any scalars <span class="tex-holder inline-math" data-source-tex="c_i \in \mathbb{R}">$c_i \in \mathbb{R}$.</span></p></div><p class="body-text">For example, the linear combination in question from the previous question was</p><p class="body-text" style="text-align: center; line-height: 0"><span class="tex-holder" style="padding: 8px" data-source-tex="$$[NEWLINE][TAB]-2\left[\begin{array}{c} 1 \\ -1 \\ 3 \end{array}\right] + \left[\begin{array}{c} -2 \\ 2 \\ -6 \end{array}\right] = \left[\begin{array}{c} 0 \\ 0 \\ 0 \end{array}\right].[NEWLINE]$$">$$\begin{align*}-2\left[\begin{array}{c} 1 \\ -1 \\ 3 \end{array}\right] + \left[\begin{array}{c} -2 \\ 2 \\ -6 \end{array}\right] = \left[\begin{array}{c} 0 \\ 0 \\ 0 \end{array}\right].\end{align*}$$</span></p><p class="body-text">Here, we&#x2019;ve written the vectors as columns to be consistent and make it easier to parse, but the equation works just as well with row vectors too (i.e. the way they appear in the augmented matrix):</p><p class="body-text" style="text-align: center; line-height: 0"><span class="tex-holder" style="padding: 8px" data-source-tex="\begin{align*}[NEWLINE][TAB]-2\left[\begin{array}{ccc} 1& -1& 3 \end{array}\right] + \left[\begin{array}{ccc} -2& 2& -6 \end{array}\right] = \left[\begin{array}{ccc} 0& 0& 0 \end{array}\right].[NEWLINE]\end{align*}">$$\begin{align*}-2\left[\begin{array}{ccc} 1& -1& 3 \end{array}\right] + \left[\begin{array}{ccc} -2& 2& -6 \end{array}\right] = \left[\begin{array}{ccc} 0& 0& 0 \end{array}\right].\end{align*}$$</span></p><p class="body-text">A linear combination that equals the zero vector is of the most interest to us: it&#x2019;s what determines whether a system of equations has a solution involving free parameters. We&#x2019;ll be talking about that situation quite a bit, so let&#x2019;s give it a name.</p><div class="notes-def notes-environment"><div class="notes-def-title notes-title">Definition: linear independence</div><p class="body-text">A collection of vectors <span class="tex-holder inline-math" data-source-tex="v_1, ..., v_k \in \mathbb{R}^n">$v_1, ..., v_k \in \mathbb{R}^n$</span> is <strong>linearly dependent</strong> if there is a linear combination of the <span class="tex-holder inline-math" data-source-tex="v_i">$v_i$</span> that is equal to the zero vector (other than the linear combination with every coefficient being <span class="tex-holder inline-math" data-source-tex="0">$0$).</span> If a collection of vectors is not linearly dependent, we say it&#x2019;s <strong>linearly independent</strong>.</p></div><div class="notes-ex notes-environment"><div class="notes-ex-title notes-title">Example: linear independence</div><p class="body-text">Are the vectors <span class="tex-holder inline-math" data-source-tex="\displaystyle \vec{v_1} = \left[\begin{array}{c} 1 \\ 2 \\ -1 \end{array}\right]">$\displaystyle \vec{v_1} = \left[\begin{array}{c} 1 \\ 2 \\ -1 \end{array}\right]$,</span> <span class="tex-holder inline-math" data-source-tex="\displaystyle \vec{v_2} = \left[\begin{array}{c} 2 \\ 0 \\ 4 \end{array}\right]">$\displaystyle \vec{v_2} = \left[\begin{array}{c} 2 \\ 0 \\ 4 \end{array}\right]$,</span> and <span class="tex-holder inline-math" data-source-tex="\displaystyle \vec{v_3} = \left[\begin{array}{c} 0 \\ 2 \\ -3 \end{array}\right]">$\displaystyle \vec{v_3} = \left[\begin{array}{c} 0 \\ 2 \\ -3 \end{array}\right]$</span> linearly independent? Why or why not?</p><div class="solution"></div><p class="body-text">For the vectors to be linearly <em>dependent</em>, we would need scalars <span class="tex-holder inline-math" data-source-tex="c_1">$c_1$,</span> <span class="tex-holder inline-math" data-source-tex="c_2">$c_2$,</span> and <span class="tex-holder inline-math" data-source-tex="c_3">$c_3$</span> so that</p><p class="body-text" style="text-align: center; line-height: 0"><span class="tex-holder" style="padding: 8px" data-source-tex="$$[NEWLINE][TAB]c_1\vec{v_1} + c_2\vec{v_2} + c_3\vec{v_3} = \vec{0}[NEWLINE]$$">$$\begin{align*}c_1\vec{v_1} + c_2\vec{v_2} + c_3\vec{v_3} = \vec{0}\end{align*}$$</span></p><p class="body-text">and not all the <span class="tex-holder inline-math" data-source-tex="c_i">$c_i$</span> are zero. A great lesson in math is to use existing theory whenever possible, and this is a great example: this is just a system of linear equations in the <span class="tex-holder inline-math" data-source-tex="c_i">$c_i$!</span> Specifically, it corresponds to the augmented matrix</p><p class="body-text" style="text-align: center; line-height: 0"><span class="tex-holder" style="padding: 8px" data-source-tex="\begin{align*}[NEWLINE][TAB]\left[\begin{array}{ccc|c} 1& 2& 0 & 0 \\ 2& 0& 2 & 0 \\ -1& 4& -3 & 0 \end{array}\right].[NEWLINE]\end{align*}">$$\begin{align*}\left[\begin{array}{ccc|c} 1& 2& 0 & 0 \\ 2& 0& 2 & 0 \\ -1& 4& -3 & 0 \end{array}\right].\end{align*}$$</span></p><p class="body-text">Take a moment to really dig into that and convince yourself of why this is the case. If it doesn&#x2019;t become clear, it&#x2019;s absolutely worth starting with the vectors, multiplying them each by their respective constant, and then adding them together.</p><p class="body-text">Now that we have the system as a matrix, we can row-reduce it to solve for the <span class="tex-holder inline-math" data-source-tex="c_i">$c_i$:</span></p><p class="body-text" style="text-align: center; line-height: 0"><span class="tex-holder" style="padding: 8px" data-source-tex="\begin{align*}[NEWLINE][TAB]\left[\begin{array}{ccc|c} 1& 2& 0 & 0 \\ 2& 0& 2 & 0 \\ -1& 4& -3 & 0 \end{array}\right] & \\[NEWLINE][TAB]\left[\begin{array}{ccc|c} 1& 2& 0 & 0 \\ 0& -4& 2 & 0 \\ 0& 6& -3 & 0 \end{array}\right] & \qquad \begin{array}{l} \vec{r_2} \to \vec{r_2} - 2\vec{r_1} \\ \vec{r_3} \to \vec{r_3} + \vec{r_1} \end{array}\\[NEWLINE][TAB]\left[\begin{array}{ccc|c} 1& 2& 0 & 0 \\ 0& 2& -1 & 0 \\ 0& 2& -1 & 0 \end{array}\right] & \qquad \begin{array}{l} \vec{r_2} \to -\frac{1}{2}\vec{r_2} \\ \vec{r_3} \to \frac{1}{3}\vec{r_3} \end{array}\\[NEWLINE][TAB]\left[\begin{array}{ccc|c} 1& 0& 1 & 0 \\ 0& 2& -1 & 0 \\ 0& 0& 0 & 0 \end{array}\right] & \qquad \begin{array}{l} \vec{r_3} \to \vec{r_3} - \vec{r_2} \\ \vec{r_1} \to \vec{r_1} - \vec{r_2} \end{array}[NEWLINE]\end{align*}">$$\begin{align*}\left[\begin{array}{ccc|c} 1& 2& 0 & 0 \\ 2& 0& 2 & 0 \\ -1& 4& -3 & 0 \end{array}\right] & \\[4px]\left[\begin{array}{ccc|c} 1& 2& 0 & 0 \\ 0& -4& 2 & 0 \\ 0& 6& -3 & 0 \end{array}\right] & \qquad \begin{array}{l} \vec{r_2} \to \vec{r_2} - 2\vec{r_1} \\ \vec{r_3} \to \vec{r_3} + \vec{r_1} \end{array}\\[4px]\left[\begin{array}{ccc|c} 1& 2& 0 & 0 \\ 0& 2& -1 & 0 \\ 0& 2& -1 & 0 \end{array}\right] & \qquad \begin{array}{l} \vec{r_2} \to -\frac{1}{2}\vec{r_2} \\ \vec{r_3} \to \frac{1}{3}\vec{r_3} \end{array}\\[4px]\left[\begin{array}{ccc|c} 1& 0& 1 & 0 \\ 0& 2& -1 & 0 \\ 0& 0& 0 & 0 \end{array}\right] & \qquad \begin{array}{l} \vec{r_3} \to \vec{r_3} - \vec{r_2} \\ \vec{r_1} \to \vec{r_1} - \vec{r_2} \end{array}\end{align*}$$</span></p><p class="body-text">Letting <span class="tex-holder inline-math" data-source-tex="c_3 = t">$c_3 = t$,</span> we have <span class="tex-holder inline-math" data-source-tex="c_1 = -t">$c_1 = -t$,</span> <span class="tex-holder inline-math" data-source-tex="c_2 = \frac{1}{2}t">$c_2 = \frac{1}{2}t$,</span> and <span class="tex-holder inline-math" data-source-tex="c_3 = t">$c_3 = t$.</span> Taking <span class="tex-holder inline-math" data-source-tex="t = 1">$t = 1$</span> for example, we have a linear combination that produces <span class="tex-holder inline-math" data-source-tex="\vec{0}">$\vec{0}$,</span> so these vectors are linearly dependent. As a gut check, we expect there to be at least one free parameter whenever vectors are linearly dependent, since if we take any linear combination of <span class="tex-holder inline-math" data-source-tex="\vec{v_1}">$\vec{v_1}$,</span> <span class="tex-holder inline-math" data-source-tex="\vec{v_2}">$\vec{v_2}$,</span> <span class="tex-holder inline-math" data-source-tex="\vec{v_3}">$\vec{v_3}$,</span> we can multiply every coefficient by any number <span class="tex-holder inline-math" data-source-tex="t">$t$</span> to produce another linear combination equaling <span class="tex-holder inline-math" data-source-tex="\vec{0}">$\vec{0}$.</span> If we had instead been able to row-reduce all the way to the identity matrix, then we would have found that <span class="tex-holder inline-math" data-source-tex="c_1 = c_2 = c_3 = 0">$c_1 = c_2 = c_3 = 0$,</span> meaning that was the only way to make a linear combination equal to <span class="tex-holder inline-math" data-source-tex="\vec{0}">$\vec{0}$</span> &mdash; and so the vectors would be linearly independent.</p></div><div class="notes-exc notes-environment"><div class="notes-exc-title notes-title">Exercise: linear independence</div><p class="body-text">Are the vectors <span class="tex-holder inline-math" data-source-tex="\displaystyle \vec{w_1} = \left[\begin{array}{c} 2 \\ 0 \\ 1 \end{array}\right]">$\displaystyle \vec{w_1} = \left[\begin{array}{c} 2 \\ 0 \\ 1 \end{array}\right]$,</span> <span class="tex-holder inline-math" data-source-tex="\displaystyle \vec{w_2} = \left[\begin{array}{c} -1 \\ -1 \\ 1 \end{array}\right]">$\displaystyle \vec{w_2} = \left[\begin{array}{c} -1 \\ -1 \\ 1 \end{array}\right]$,</span> and <span class="tex-holder inline-math" data-source-tex="\displaystyle \vec{w_3} = \left[\begin{array}{c} 0 \\ 1 \\ 0 \end{array}\right]">$\displaystyle \vec{w_3} = \left[\begin{array}{c} 0 \\ 1 \\ 0 \end{array}\right]$</span> linearly independent? Why or why not?</p><div class="solution"></div><p class="body-text">We set up the matrix as before, placing these vectors as columns, and then row reduce.</p><p class="body-text" style="text-align: center; line-height: 0"><span class="tex-holder" style="padding: 8px" data-source-tex="\begin{align*}[NEWLINE][TAB]\left[\begin{array}{ccc} 2& -1& 0 \\ 0& -1& 1 \\ 1& 1& 0 \end{array}\right] & \\[NEWLINE][TAB]\left[\begin{array}{ccc} 1& 1& 0 \\ 0& 1& -1 \\ 2& -1& 0 \end{array}\right] & \qquad \begin{array}{l} \vec{r_1} \leftrightarrow \vec{r_3} \\ \vec{r_2} \to -\vec{r_2} \end{array}\\[NEWLINE][TAB]\left[\begin{array}{ccc} 1& 1& 0 \\ 0& 1& -1 \\ 0& -3& 0 \end{array}\right] & \qquad \vec{r_3} \to \vec{r_3} - 2\vec{r_1}\\[NEWLINE][TAB]\left[\begin{array}{ccc} 1& 1& 0 \\ 0& 1& 0 \\ 0& 0& -3 \end{array}\right] & \qquad \vec{r_3} \to \vec{r_3} + 3\vec{r_2}\\[NEWLINE][TAB]\left[\begin{array}{ccc} 1& 1& 0 \\ 0& 1& 0 \\ 0& 0& 1 \end{array}\right] & \qquad \vec{r_3} \to -\frac{1}{3}\vec{r_3}\\[NEWLINE][TAB]\left[\begin{array}{ccc} 1& 0& 0 \\ 0& 1& 0 \\ 0& 0& 1 \end{array}\right] & \qquad \vec{r_1} \to \vec{r_1} - \vec{r_2}[NEWLINE]\end{align*}">$$\begin{align*}\left[\begin{array}{ccc} 2& -1& 0 \\ 0& -1& 1 \\ 1& 1& 0 \end{array}\right] & \\[4px]\left[\begin{array}{ccc} 1& 1& 0 \\ 0& 1& -1 \\ 2& -1& 0 \end{array}\right] & \qquad \begin{array}{l} \vec{r_1} \leftrightarrow \vec{r_3} \\ \vec{r_2} \to -\vec{r_2} \end{array}\\[4px]\left[\begin{array}{ccc} 1& 1& 0 \\ 0& 1& -1 \\ 0& -3& 0 \end{array}\right] & \qquad \vec{r_3} \to \vec{r_3} - 2\vec{r_1}\\[4px]\left[\begin{array}{ccc} 1& 1& 0 \\ 0& 1& 0 \\ 0& 0& -3 \end{array}\right] & \qquad \vec{r_3} \to \vec{r_3} + 3\vec{r_2}\\[4px]\left[\begin{array}{ccc} 1& 1& 0 \\ 0& 1& 0 \\ 0& 0& 1 \end{array}\right] & \qquad \vec{r_3} \to -\frac{1}{3}\vec{r_3}\\[4px]\left[\begin{array}{ccc} 1& 0& 0 \\ 0& 1& 0 \\ 0& 0& 1 \end{array}\right] & \qquad \vec{r_1} \to \vec{r_1} - \vec{r_2}\end{align*}$$</span></p><p class="body-text">These vectors are linearly independent! The only solution for the coefficients <span class="tex-holder inline-math" data-source-tex="c_i">$c_i$</span> is <span class="tex-holder inline-math" data-source-tex="c_1 = c_2 = c_3 = 0">$c_1 = c_2 = c_3 = 0$,</span> so there is no nonzero linear combination of the <span class="tex-holder inline-math" data-source-tex="c_i">$c_i$</span> that makes the zero vector.</p></div><p class="body-text">We&#x2019;ll have a lot to say about linear combinations &mdash; most notably, they&#x2019;re a valuable alternate perspective on matrix multiplication. For an example, let&#x2019;s look at the product</p><p class="body-text" style="text-align: center; line-height: 0"><span class="tex-holder" style="padding: 8px" data-source-tex="\begin{align*}[NEWLINE][TAB]\left[\begin{array}{cc} a& b \\ c& d \end{array}\right] \left[\begin{array}{c} 4 \\ 2 \end{array}\right] = \left[\begin{array}{c} 4a + 2b \\ 4c + 2d \end{array}\right] = 4 \left[\begin{array}{c} a \\ c \end{array}\right] + 2 \left[\begin{array}{c} b \\ d \end{array}\right].[NEWLINE]\end{align*}">$$\begin{align*}\left[\begin{array}{cc} a& b \\ c& d \end{array}\right] \left[\begin{array}{c} 4 \\ 2 \end{array}\right] = \left[\begin{array}{c} 4a + 2b \\ 4c + 2d \end{array}\right] = 4 \left[\begin{array}{c} a \\ c \end{array}\right] + 2 \left[\begin{array}{c} b \\ d \end{array}\right].\end{align*}$$</span></p><p class="body-text">Here we can see a property we&#x2019;ll reference for the remainder of the course: <strong>a matrix times a vector is a linear combination of the columns of the matrix, with coefficients given by the entries of the vector</strong>.</p><p class="body-text">That may be long, but it will more than make up for it in usefulness. As a first application, the <strong>range</strong> of the matrix (i.e. its set of possible outputs) is given by <em>all</em> linear combinations of the columns of the matrix, and so we&#x2019;d do well to give that concept a name. We&#x2019;ll return to the concept of the range of a matrix in the future, but for now, we&#x2019;ll focus on the set of linear combinations.</p><div class="notes-def notes-environment"><div class="notes-def-title notes-title">Definition: span</div><p class="body-text">The <strong>span</strong> of vectors <span class="tex-holder inline-math" data-source-tex="\vec{v_1}, ..., \vec{v_k} \in \mathbb{R}^n">$\vec{v_1}, ..., \vec{v_k} \in \mathbb{R}^n$</span> is the set of <em>all</em> linear combinations of them, denoted</p><p class="body-text" style="text-align: center; line-height: 0"><span class="tex-holder" style="padding: 8px" data-source-tex="$$[NEWLINE][TAB]\operatorname{span}\{v_1, ..., v_k\} = \left\{ c_1\vec{v_1} + \cdots + c_k\vec{v_k} \in \mathbb{R}^n \mid c_1, ..., c_k \in \mathbb{R} \right\}.[NEWLINE]$$">$$\begin{align*}\operatorname{span}\{v_1, ..., v_k\} = \left\{ c_1\vec{v_1} + \cdots + c_k\vec{v_k} \in \mathbb{R}^n \mid c_1, ..., c_k \in \mathbb{R} \right\}.\end{align*}$$</span></p></div><div class="notes-exc notes-environment"><div class="notes-exc-title notes-title">Exercise: span</div><p class="body-text numbered-list-item">1. What does the span of a single nonzero vector look like in <span class="tex-holder inline-math" data-source-tex="\mathbb{R}^2">$\mathbb{R}^2$?</span> What about <span class="tex-holder inline-math" data-source-tex="\mathbb{R}^3">$\mathbb{R}^3$?</span> Does this match what we already know?</p><p class="body-text numbered-list-item">2. What is the span of the zero vector?</p><p class="body-text numbered-list-item">3. What does the span of two nonzero vectors look like in <span class="tex-holder inline-math" data-source-tex="\mathbb{R}^3">$\mathbb{R}^3$?</span> What about <span class="tex-holder inline-math" data-source-tex="\mathbb{R}^2">$\mathbb{R}^2$?</span></p><div class="solution"></div><p class="body-text numbered-list-item">1. This is the line through the origin parallel to the vector, which tracks with the formula we already have for lines in <span class="tex-holder inline-math" data-source-tex="\mathbb{R}^3">$\mathbb{R}^3$!</span></p><p class="body-text numbered-list-item">2. The span of the zero vector is just the zero vector, and more generally, adding the zero vector to any set of vectors doesn&#x2019;t change its span.</p><p class="body-text numbered-list-item">3. In <span class="tex-holder inline-math" data-source-tex="\mathbb{R}^3">$\mathbb{R}^3$,</span> the span of two <em>linearly independent</em> vectors is the plane containing them. The span of two linearly dependent vectors is the line containing them both! The same goes in <span class="tex-holder inline-math" data-source-tex="\mathbb{R}^2">$\mathbb{R}^2$</span> &mdash; the span is either all of <span class="tex-holder inline-math" data-source-tex="\mathbb{R}^2">$\mathbb{R}^2$</span> or a line through the origin.</p></div><p class="body-text">When a collection of vectors <span class="tex-holder inline-math" data-source-tex="\vec{v_1}, ..., \vec{v_k} \in \mathbb{R}^n">$\vec{v_1}, ..., \vec{v_k} \in \mathbb{R}^n$</span> has at least <span class="tex-holder inline-math" data-source-tex="n">$n$</span> linearly independent ones, then <span class="tex-holder inline-math" data-source-tex="\operatorname{span}\{\vec{v_1}, ..., \vec{v_k}\} = \mathbb{R}^n">$\operatorname{span}\{\vec{v_1}, ..., \vec{v_k}\} = \mathbb{R}^n$:</span> that&#x2019;s because we can take just the <span class="tex-holder inline-math" data-source-tex="n">$n$</span> linearly independent vectors and row reduce them as rows in a matrix to get to the identity matrix, so all the vectors <span class="tex-holder inline-math" data-source-tex="\vec{e_i}">$\vec{e_i}$</span> that are all zero except for a one in the <span class="tex-holder inline-math" data-source-tex="i">$i$th</span> position are expressible as linear combinations of the <span class="tex-holder inline-math" data-source-tex="\vec{v_j}">$\vec{v_j}$,</span> and every vector in <span class="tex-holder inline-math" data-source-tex="\mathbb{R}^n">$\mathbb{R}^n$</span> is expressible as a linear combination of the <span class="tex-holder inline-math" data-source-tex="\vec{e_i}">$\vec{e_i}$.</span></p><p class="body-text">Similarly, when a collection of vectors <span class="tex-holder inline-math" data-source-tex="\vec{v_1}, ..., \vec{v_k} \in \mathbb{R}^n">$\vec{v_1}, ..., \vec{v_k} \in \mathbb{R}^n$</span> has <span class="tex-holder inline-math" data-source-tex="k > n">$k > n$,</span> so there are more vectors than entries per vector, then the vectors have to be linearly dependent. To see this, place them all as rows in a matrix to produce one that&#x2019;s taller than it is wide, and then row reduce it. At least one of the rows has to be all zero in the end, so the vectors must be linearly dependent. Let&#x2019;s summarize these results properly.</p><div class="notes-prop notes-environment"><div class="notes-prop-title notes-title">Proposition: conditions for linear independence and spanning</div><p class="body-text">Let <span class="tex-holder inline-math" data-source-tex="\vec{v_1}, ..., \vec{v_k} \in \mathbb{R}^n">$\vec{v_1}, ..., \vec{v_k} \in \mathbb{R}^n$.</span></p><p class="body-text numbered-list-item">1. If <span class="tex-holder inline-math" data-source-tex="k > n">$k > n$,</span> then the vectors cannot be linearly independent. Equivalently, if the vectors are linearly independent, then <span class="tex-holder inline-math" data-source-tex="k \leq n">$k \leq n$.</span></p><p class="body-text numbered-list-item">2. If <span class="tex-holder inline-math" data-source-tex="k < n">$k < n$,</span> then the vectors cannot span <span class="tex-holder inline-math" data-source-tex="\mathbb{R}^n">$\mathbb{R}^n$.</span> Equivalently, if the vectors do span <span class="tex-holder inline-math" data-source-tex="\mathbb{R}^n">$\mathbb{R}^n$,</span> then <span class="tex-holder inline-math" data-source-tex="k \geq n">$k \geq n$.</span></p><p class="body-text numbered-list-item">3. If there are at least <span class="tex-holder inline-math" data-source-tex="n">$n$</span> different linearly independent vectors among the <span class="tex-holder inline-math" data-source-tex="\vec{v_i}">$\vec{v_i}$,</span> then <span class="tex-holder inline-math" data-source-tex="\operatorname{span}\left\{ \vec{v_1}, ..., \vec{v_k} \right\} = \mathbb{R}^n">$\operatorname{span}\left\{ \vec{v_1}, ..., \vec{v_k} \right\} = \mathbb{R}^n$.</span></p></div></section><h2 class="section-text">Bases</h2><section><p class="body-text">When we take a vector <span class="tex-holder inline-math" data-source-tex="\vec{v}">$\vec{v}$</span> in the span of some linearly independent vectors <span class="tex-holder inline-math" data-source-tex="\vec{v_1}, ..., \vec{v_k} \in \mathbb{R}^n">$\vec{v_1}, ..., \vec{v_k} \in \mathbb{R}^n$,</span> it&#x2019;s not only a linear combination, but it&#x2019;s also unique: if there were two different ways to write</p><p class="body-text" style="text-align: center; line-height: 0"><span class="tex-holder" style="padding: 8px" data-source-tex="$$[NEWLINE][TAB]\vec{v} = c_1\vec{v_1} + \cdots + c_k\vec{v_k} = d_1\vec{v_1} + \cdots + d_k\vec{v_k},[NEWLINE]$$">$$\begin{align*}\vec{v} = c_1\vec{v_1} + \cdots + c_k\vec{v_k} = d_1\vec{v_1} + \cdots + d_k\vec{v_k},\end{align*}$$</span></p><p class="body-text">then subtracting,</p><p class="body-text" style="text-align: center; line-height: 0"><span class="tex-holder" style="padding: 8px" data-source-tex="\begin{align*}[NEWLINE][TAB]c_1\vec{v_1} + \cdots + c_k\vec{v_k} - \left( d_1\vec{v_1} + \cdots + d_k\vec{v_k} \right) &= \vec{0}\\[NEWLINE][TAB](c_1 - d_1) \vec{v_1} + \cdots + (c_k - d_k)\vec{v_k} = \vec{0}.[NEWLINE]\end{align*}">$$\begin{align*}c_1\vec{v_1} + \cdots + c_k\vec{v_k} - \left( d_1\vec{v_1} + \cdots + d_k\vec{v_k} \right) &= \vec{0}\\[4px](c_1 - d_1) \vec{v_1} + \cdots + (c_k - d_k)\vec{v_k} = \vec{0}.\end{align*}$$</span></p><p class="body-text">But since the <span class="tex-holder inline-math" data-source-tex="\vec{v_i}">$\vec{v_i}$</span> were linearly independent, the only linear combination that equals the zero vector is when all of the coefficients are zero, meaning <span class="tex-holder inline-math" data-source-tex="c_i - d_i = 0">$c_i - d_i = 0$</span> for all <span class="tex-holder inline-math" data-source-tex="i">$i$.</span> The result is that <span class="tex-holder inline-math" data-source-tex="c_i = d_i">$c_i = d_i$</span> for all <span class="tex-holder inline-math" data-source-tex="i">$i$,</span> and so there wasn&#x2019;t a different way to write <span class="tex-holder inline-math" data-source-tex="\vec{v}">$\vec{v}$</span> after all!</p><p class="body-text">This uniqueness of expression is a valuable consequence of linear independence, and it&#x2019;s even nicer when the vectors span all of <span class="tex-holder inline-math" data-source-tex="\mathbb{R}^n">$\mathbb{R}^n$,</span> so that <em>every</em> vector in <span class="tex-holder inline-math" data-source-tex="\mathbb{R}^n">$\mathbb{R}^n$</span> can be expressed uniquely as a linear combination. Let&#x2019;s give that case a name!</p><div class="notes-def notes-environment"><div class="notes-def-title notes-title">Definition: basis for <span class="tex-holder inline-math" data-source-tex="\mathbb{R}^n">$\mathbb{R}^n$</span></div><p class="body-text">A <strong>basis</strong> for <span class="tex-holder inline-math" data-source-tex="\mathbb{R}^n">$\mathbb{R}^n$</span> is a collection of vectors <span class="tex-holder inline-math" data-source-tex="\vec{v_1}, \vec{v_2}, ..., \vec{v_n} \in \mathbb{R}^n">$\vec{v_1}, \vec{v_2}, ..., \vec{v_n} \in \mathbb{R}^n$</span> that is linearly independent and spans <span class="tex-holder inline-math" data-source-tex="\mathbb{R}^n">$\mathbb{R}^n$.</span> Given a basis and any vector <span class="tex-holder inline-math" data-source-tex="\vec{v} \in \mathbb{R}^n">$\vec{v} \in \mathbb{R}^n$,</span> there is a <strong>unique</strong> linear combination</p><p class="body-text" style="text-align: center; line-height: 0"><span class="tex-holder" style="padding: 8px" data-source-tex="$$[NEWLINE][TAB]c_1\vec{v_1} + c_2\vec{v_2} + \cdots + c_n\vec{v_n} = \vec{v}.[NEWLINE]$$">$$\begin{align*}c_1\vec{v_1} + c_2\vec{v_2} + \cdots + c_n\vec{v_n} = \vec{v}.\end{align*}$$</span></p></div><p class="body-text">The previous proposition tells us that any basis for <span class="tex-holder inline-math" data-source-tex="\mathbb{R}^n">$\mathbb{R}^n$</span> must have exactly <span class="tex-holder inline-math" data-source-tex="n">$n$</span> vectors: it can&#x2019;t have more, since then the vectors couldn&#x2019;t be linearly independent, and it can&#x2019;t have less, since then they couldn&#x2019;t span <span class="tex-holder inline-math" data-source-tex="\mathbb{R}^n">$\mathbb{R}^n$.</span> Moreover, if we&#x2019;re interested in checking if a collection of vectors is a basis, then we can just check if they&#x2019;re linearly independent and have the right number of vectors, since then they&#x2019;ll be guaranteed to span the space too.</p><div class="notes-ex notes-environment"><div class="notes-ex-title notes-title">Example: a basis for <span class="tex-holder inline-math" data-source-tex="\mathbb{R}^n">$\mathbb{R}^n$</span></div><p class="body-text">The primordial example of a basis is the vectors</p><p class="body-text" style="text-align: center; line-height: 0"><span class="tex-holder" style="padding: 8px" data-source-tex="$$[NEWLINE][TAB]\vec{e_1} = \left[\begin{array}{c} 1 \\ 0 \\ 0 \\ \vdots \\ 0 \end{array}\right], \vec{e_2} = \left[\begin{array}{c} 0 \\ 1 \\ 0 \\ \vdots \\ 0 \end{array}\right], ..., \vec{e_n} = \left[\begin{array}{c} 0 \\ 0 \\ \vdots \\ 0 \\ 1 \end{array}\right] \in \mathbb{R}^n.[NEWLINE]$$">$$\begin{align*}\vec{e_1} = \left[\begin{array}{c} 1 \\ 0 \\ 0 \\ \vdots \\ 0 \end{array}\right], \vec{e_2} = \left[\begin{array}{c} 0 \\ 1 \\ 0 \\ \vdots \\ 0 \end{array}\right], ..., \vec{e_n} = \left[\begin{array}{c} 0 \\ 0 \\ \vdots \\ 0 \\ 1 \end{array}\right] \in \mathbb{R}^n.\end{align*}$$</span></p><p class="body-text">The <span class="tex-holder inline-math" data-source-tex="\vec{e_i}">$\vec{e_i}$</span> are linearly independent since they&#x2019;re already the rows of the identity matrix, and they certainly span <span class="tex-holder inline-math" data-source-tex="\mathbb{R}^n">$\mathbb{R}^n$:</span> given a vector <span class="tex-holder inline-math" data-source-tex="\vec{v} \in \mathbb{R}^n">$\vec{v} \in \mathbb{R}^n$,</span> we can immediately express <span class="tex-holder inline-math" data-source-tex="\vec{v}">$\vec{v}$</span> as a linear combination of the <span class="tex-holder inline-math" data-source-tex="\vec{e_i}">$\vec{e_i}$</span> by just using the entries of <span class="tex-holder inline-math" data-source-tex="\vec{v}">$\vec{v}$</span> as coefficients.</p></div><p class="body-text">This basis is so common that we&#x2019;ll want a name for it &mdash; it&#x2019;s called the <strong>standard basis for <span class="tex-holder inline-math" data-source-tex="\mathbb{R}^n">$\mathbb{R}^n$</strong>.</span> The name implies it&#x2019;s not the only one, though, and that&#x2019;s definitely the case. Let&#x2019;s take a look at some more unusual ones.</p><div class="notes-ex notes-environment"><div class="notes-ex-title notes-title">Example: another basis for <span class="tex-holder inline-math" data-source-tex="\mathbb{R}^n">$\mathbb{R}^n$</span></div><p class="body-text">Show that the vectors</p><p class="body-text" style="text-align: center; line-height: 0"><span class="tex-holder" style="padding: 8px" data-source-tex="$$[NEWLINE][TAB]\vec{v_1} = \left[\begin{array}{c} 3 \\ 1 \\ 2 \end{array}\right], \qquad \vec{v_2} = \left[\begin{array}{c} 1 \\ 0 \\ 1 \end{array}\right], \qquad \vec{v_3} = \left[\begin{array}{c} 0 \\ 2 \\ 1 \end{array}\right][NEWLINE]$$">$$\begin{align*}\vec{v_1} = \left[\begin{array}{c} 3 \\ 1 \\ 2 \end{array}\right], \qquad \vec{v_2} = \left[\begin{array}{c} 1 \\ 0 \\ 1 \end{array}\right], \qquad \vec{v_3} = \left[\begin{array}{c} 0 \\ 2 \\ 1 \end{array}\right]\end{align*}$$</span></p><p class="body-text">form a basis for <span class="tex-holder inline-math" data-source-tex="\mathbb{R}^3">$\mathbb{R}^3$</span> and express the vector</p><p class="body-text" style="text-align: center; line-height: 0"><span class="tex-holder" style="padding: 8px" data-source-tex="$$[NEWLINE][TAB]\vec{v} = \left[\begin{array}{c} 4 \\ 1 \\ 0 \end{array}\right][NEWLINE]$$">$$\begin{align*}\vec{v} = \left[\begin{array}{c} 4 \\ 1 \\ 0 \end{array}\right]\end{align*}$$</span></p><p class="body-text">in this basis.</p><p class="body-text">While this is nominally a new kind of task, it just comes down to more row reduction: we know that there is the correct number of vectors for a basis (three) and so we can just check linear independence. As a small extra, let&#x2019;s row reduce these by rows instead of columns: that&#x2019;s perfectly find to do for showing linear independence, and for interesting reasons that we&#x2019;ll have a chance to explore on the homework.</p><p class="body-text" style="text-align: center; line-height: 0"><span class="tex-holder" style="padding: 8px" data-source-tex="\begin{align*}[NEWLINE][TAB]\left[\begin{array}{ccc} 3& 1& 2 \\ 1& 0& 1 \\ 0& 2& 1 \end{array}\right] &\\[NEWLINE][TAB]\left[\begin{array}{ccc} 0& 1& -1 \\ 1& 0& 1 \\ 0& 2& 1 \end{array}\right] & \qquad \vec{r_1} \to \vec{r_1} - 3\vec{r_2}\\[NEWLINE][TAB]\left[\begin{array}{ccc} 0& 1& -1 \\ 1& 0& 1 \\ 0& 0& 3 \end{array}\right] & \qquad \vec{r_3} \to \vec{r_3} - 2\vec{r_1}\\[NEWLINE][TAB]\left[\begin{array}{ccc} 0& 1& -1 \\ 1& 0& 1 \\ 0& 0& 1 \end{array}\right] & \qquad \vec{r_3} \to \frac{1}{3}\vec{r_3}\\[NEWLINE][TAB]\left[\begin{array}{ccc} 0& 1& 0 \\ 1& 0& 1 \\ 0& 0& 1 \end{array}\right] & \qquad \begin{array}{l} \vec{r_2} \to \vec{r_2} - \vec{r_3} \\ \vec{r_1} \to \vec{r_1} + \vec{r_3} \end{array},[NEWLINE]\end{align*}">$$\begin{align*}\left[\begin{array}{ccc} 3& 1& 2 \\ 1& 0& 1 \\ 0& 2& 1 \end{array}\right] &\\[4px]\left[\begin{array}{ccc} 0& 1& -1 \\ 1& 0& 1 \\ 0& 2& 1 \end{array}\right] & \qquad \vec{r_1} \to \vec{r_1} - 3\vec{r_2}\\[4px]\left[\begin{array}{ccc} 0& 1& -1 \\ 1& 0& 1 \\ 0& 0& 3 \end{array}\right] & \qquad \vec{r_3} \to \vec{r_3} - 2\vec{r_1}\\[4px]\left[\begin{array}{ccc} 0& 1& -1 \\ 1& 0& 1 \\ 0& 0& 1 \end{array}\right] & \qquad \vec{r_3} \to \frac{1}{3}\vec{r_3}\\[4px]\left[\begin{array}{ccc} 0& 1& 0 \\ 1& 0& 1 \\ 0& 0& 1 \end{array}\right] & \qquad \begin{array}{l} \vec{r_2} \to \vec{r_2} - \vec{r_3} \\ \vec{r_1} \to \vec{r_1} + \vec{r_3} \end{array},\end{align*}$$</span></p><p class="body-text">and so all of the vectors are linearly independent and therefore span <span class="tex-holder inline-math" data-source-tex="\mathbb{R}^3">$\mathbb{R}^3$.</span></p><p class="body-text">To express <span class="tex-holder inline-math" data-source-tex="\vec{v}">$\vec{v}$</span> in the basis, we&#x2019;re just trying to find a linear combination of the basis vectors that equals <span class="tex-holder inline-math" data-source-tex="\vec{v}">$\vec{v}$.</span> We&#x2019;ve already solved that type of problem: it&#x2019;s just row reduction once again, this time with the <span class="tex-holder inline-math" data-source-tex="\vec{v_i}">$\vec{v_i}$</span> as columns.</p><p class="body-text" style="text-align: center; line-height: 0"><span class="tex-holder" style="padding: 8px" data-source-tex="\begin{align*}[NEWLINE][TAB]\left[\begin{array}{ccc|c} 3& 1& 0 & 4 \\ 1& 0& 2 & 1 \\ 2& 1& 1 & 0 \end{array}\right] & \\[NEWLINE][TAB]\left[\begin{array}{ccc|c} 1& 0& 2 & 1 \\ 3& 1& 0 & 4 \\ 2& 1& 1 & 0 \end{array}\right] & \qquad \vec{r_1} \leftrightarrow \vec{r_2}\\[NEWLINE][TAB]\left[\begin{array}{ccc|c} 1& 0& 2 & 1 \\ 0& 1& -6 & 1 \\ 0& 1& -3 & -2 \end{array}\right] & \qquad \begin{array}{l} \vec{r_2} \to \vec{r_2} - 3\vec{r_1} \\ \vec{r_3} \to \vec{r_3} - 2\vec{r_1} \end{array}\\[NEWLINE][TAB]\left[\begin{array}{ccc|c} 1& 0& 2 & 1 \\ 0& 1& -6 & 1 \\ 0& 0& 3 & -3 \end{array}\right] & \qquad \vec{r_3} \to \vec{r_3} - \vec{r_2}\\[NEWLINE][TAB]\left[\begin{array}{ccc|c} 1& 0& 2 & 1 \\ 0& 1& -6 & 1 \\ 0& 0& 1 & -1 \end{array}\right] & \qquad \vec{r_3} \to \frac{1}{3}\vec{r_3}\\[NEWLINE][TAB]\left[\begin{array}{ccc|c} 1& 0& 2 & 1 \\ 0& 1& 0 & -5 \\ 0& 0& 1 & -1 \end{array}\right] & \qquad \vec{r_2} \to \vec{r_2} + 6\vec{r_3}\\[NEWLINE][TAB]\left[\begin{array}{ccc|c} 1& 0& 0 & 3 \\ 0& 1& 0 & -5 \\ 0& 0& 1 & -3 \end{array}\right] & \qquad \vec{r_1} \to \vec{r_1} - 2\vec{r_3}.[NEWLINE]\end{align*}">$$\begin{align*}\left[\begin{array}{ccc|c} 3& 1& 0 & 4 \\ 1& 0& 2 & 1 \\ 2& 1& 1 & 0 \end{array}\right] & \\[4px]\left[\begin{array}{ccc|c} 1& 0& 2 & 1 \\ 3& 1& 0 & 4 \\ 2& 1& 1 & 0 \end{array}\right] & \qquad \vec{r_1} \leftrightarrow \vec{r_2}\\[4px]\left[\begin{array}{ccc|c} 1& 0& 2 & 1 \\ 0& 1& -6 & 1 \\ 0& 1& -3 & -2 \end{array}\right] & \qquad \begin{array}{l} \vec{r_2} \to \vec{r_2} - 3\vec{r_1} \\ \vec{r_3} \to \vec{r_3} - 2\vec{r_1} \end{array}\\[4px]\left[\begin{array}{ccc|c} 1& 0& 2 & 1 \\ 0& 1& -6 & 1 \\ 0& 0& 3 & -3 \end{array}\right] & \qquad \vec{r_3} \to \vec{r_3} - \vec{r_2}\\[4px]\left[\begin{array}{ccc|c} 1& 0& 2 & 1 \\ 0& 1& -6 & 1 \\ 0& 0& 1 & -1 \end{array}\right] & \qquad \vec{r_3} \to \frac{1}{3}\vec{r_3}\\[4px]\left[\begin{array}{ccc|c} 1& 0& 2 & 1 \\ 0& 1& 0 & -5 \\ 0& 0& 1 & -1 \end{array}\right] & \qquad \vec{r_2} \to \vec{r_2} + 6\vec{r_3}\\[4px]\left[\begin{array}{ccc|c} 1& 0& 0 & 3 \\ 0& 1& 0 & -5 \\ 0& 0& 1 & -3 \end{array}\right] & \qquad \vec{r_1} \to \vec{r_1} - 2\vec{r_3}.\end{align*}$$</span></p><p class="body-text">In total, our linear combination is <span class="tex-holder inline-math" data-source-tex="\vec{v} = 3\vec{v_1} - 5\vec{v_2} - 3\vec{v_3}">$\vec{v} = 3\vec{v_1} - 5\vec{v_2} - 3\vec{v_3}$.</span> Geometrically, we can think of this expansion as meaning that the coordinates of <span class="tex-holder inline-math" data-source-tex="\vec{v}">$\vec{v}$</span> are <span class="tex-holder inline-math" data-source-tex="(3, -5, -3)">$(3, -5, -3)$</span> in a strange coordinate system where the axes are parallel to <span class="tex-holder inline-math" data-source-tex="\vec{v_1}">$\vec{v_1}$,</span> <span class="tex-holder inline-math" data-source-tex="\vec{v_2}">$\vec{v_2}$,</span> and <span class="tex-holder inline-math" data-source-tex="\vec{v_3}">$\vec{v_3}$.</span></p></div><p class="body-text">Let&#x2019;s dig into that coordinate system idea a little more. In <span class="tex-holder inline-math" data-source-tex="\mathbb{R}^2">$\mathbb{R}^2$,</span> the standard basis produces the typical coordinate system we&#x2019;re used to, while other bases produce coordinate systems that are stretched and scaled, but still perfectly functional at assigning a unique coordinate pair to every point. </p><div class="desmos-border"><div id="coordinateSystems" class="desmos-container"></div></div><p class="body-text">Here, the purple grid shows the coordinates assigned by the basis <span class="tex-holder inline-math" data-source-tex="\left\{ \left[\begin{array}{c} -1 \\ 1 \end{array}\right], \left[\begin{array}{c} 2 \\ 1 \end{array}\right] \right\}">$\left\{ \left[\begin{array}{c} -1 \\ 1 \end{array}\right], \left[\begin{array}{c} 2 \\ 1 \end{array}\right] \right\}$.</span> The blue point is called <span class="tex-holder inline-math" data-source-tex="(3, 3)">$(3, 3)$</span> in the standard basis, but <span class="tex-holder inline-math" data-source-tex="(1, 2)">$(1, 2)$</span> in this alternate one.</p><div class="notes-exc notes-environment"><div class="notes-exc-title notes-title">Exercise: another basis for <span class="tex-holder inline-math" data-source-tex="\mathbb{R}^n">$\mathbb{R}^n$</span></div><p class="body-text">Show that the vectors</p><p class="body-text" style="text-align: center; line-height: 0"><span class="tex-holder" style="padding: 8px" data-source-tex="$$[NEWLINE][TAB]\vec{v_1} = \left[\begin{array}{c} 1 \\ 2 \end{array}\right], \qquad \vec{v_2} = \left[\begin{array}{c} 0 \\ -1 \end{array}\right][NEWLINE]$$">$$\begin{align*}\vec{v_1} = \left[\begin{array}{c} 1 \\ 2 \end{array}\right], \qquad \vec{v_2} = \left[\begin{array}{c} 0 \\ -1 \end{array}\right]\end{align*}$$</span></p><p class="body-text">form a basis for <span class="tex-holder inline-math" data-source-tex="\mathbb{R}^2">$\mathbb{R}^2$,</span> and express the vector</p><p class="body-text" style="text-align: center; line-height: 0"><span class="tex-holder" style="padding: 8px" data-source-tex="$$[NEWLINE][TAB]\vec{v} = \left[\begin{array}{c} 3 \\ 8 \end{array}\right][NEWLINE]$$">$$\begin{align*}\vec{v} = \left[\begin{array}{c} 3 \\ 8 \end{array}\right]\end{align*}$$</span></p><p class="body-text">in this basis.</p></div><div class="text-buttons nav-buttons"><div class="focus-on-child" tabindex="1"><button class="text-button linked-text-button nav-button previous-nav-button" type="button" tabindex="-1">Previous</button></div><div class="focus-on-child" tabindex="1"><button class="text-button linked-text-button nav-button home-nav-button" type="button" tabindex="-1">Home</button></div><div class="focus-on-child" tabindex="1"><button class="text-button linked-text-button nav-button next-nav-button" type="button" tabindex="-1">Next</button></div></div></section></main>