# Section 10: Applications of Taylor Series

### nav-buttons

In this final section, we&#x2019;ll use Taylor series to their full extent, solving particularly difficult differential equations and integrals that were previously impossible. We&#x2019;ve seen techniques to solve both in Caclulus II, but that was far from a complete description: for example, the differential equation

$$
	y'' = xy
$$

and the integral

$$
	\int e^{-x^2}\,dx
$$

both present substantial challanges. By the end of this section, we&#x2019;ll be able to solve both with Taylor series, and the theory we started developing ten sections ago will largely be complete. Before we dive in, let&#x2019;s briefly restate the most important Taylor series we know. If possible, we like to center them at $x = 0$, which occasionally involves adjusting the argument of the function in consideration to make the math work out more easily. After each series is its interval of convergence.

$$
	\begin{align*}
		\frac{1}{1 - x} &= \sum_{n = 0}^\infty x^n = 1 + x + x^2 + x^3 + \cdots & (-1, 1)\\
		e^x &= \sum_{n = 0}^\infty \frac{x^n}{n!} = 1 + x + \frac{x^2}{2!} + \frac{x^3}{3!} + \cdots & (-\infty, \infty)\\
		\ln(1 + x) &= \sum_{n = 1}^\infty (-1)^{n + 1} \frac{x^n}{n} = x - \frac{x^2}{2} + \frac{x^3}{3} - \frac{x^4}{4} + \cdots & (-1, 1]\\
		\sin(x) &= \sum_{n = 0}^\infty (-1)^n \frac{x^{2n+1}}{(2n+1)!} = x - \frac{x^3}{3!} - \frac{x^5}{5!} + \frac{x^7}{7!} - \cdots & (-\infty, \infty)\\
		\cos(x) &= \sum_{n = 0}^\infty (-1)^n \frac{x^{2n}}{(2n)!} = 1 - \frac{x^2}{2!} - \frac{x^4}{4!} + \frac{x^6}{6!} - \cdots & (-\infty, \infty)
	\end{align*}
$$



## Power Functions and Binomial Coefficients

While that list covers most of the functions we typically come across, there&#x2019;s one glaring omission: power functions! Something as simple as $x^{1/2}$ leaves us unable to form a Taylor series, and before we jump into differential equations and integrals, we&#x2019;ll need to patch up this gap in our knowledge.

As with natural log, the math works out *much* more easily if we consider the function $f(x) = (1 + x)^r$ rather than just $x^r$. This is because we&#x2019;d ideally like to center our series at $x = 0$, and power functions don&#x2019;t do too well there. For some, like $x^{1/2}$, that&#x2019;s the edge of their domain, so our radius of convergence would be forced to be zero. For others, like $x^{1/3}$, the derivative at zero is undefined since the tangent line is vertical, meaning we couldn&#x2019;t extract the Taylor coefficients we need in the first place. By adding $1$ and centering at $0$, we&#x2019;re effectively centering a series for $x^r$ at $x = 1$, which will turn out to be perfect.

So, with $f(x) = (1 + x)^r$ for a real number $r$, what is $f^{(n)}(0)$? That&#x2019;s not too bad to figure out: just apply the power rule $n$ times. We wind up with

$$
	\begin{align*}
		f'(x) &= r(1 + x)^{r - 1}\\
		f''(x) &= r(r - 1)(1 + x)^{r - 2}\\
		f'''(x) &= r(r - 1)(r - 2)(1 + x)^{r - 3}\\
		& \ \ \vdots\\
		f^{(n)}(x) &= r(r - 1)(r - 2) \cdots (r - n + 1)(1 + x)^{r - n}.
	\end{align*}
$$

The last factor being $r - n + 1$ and not $r - n$ is a little confusing at first, but it&#x2019;s because we start at $r = 0$.

To get Taylor coefficients out of this, we need to evaluate at zero and divide by $n!$. Conveniently, setting $x = 0$ makes $(1 + x)^{r - n} = 1$, so we just have

$$
	\frac{f^{(n)}(0)}{n!} = \frac{r(r - 1)(r - 2) \cdots (r - n + 1)}{n!}.
$$

You might recognize this expression: when $r$ is a positive integer larger than $n$, the top of the fraction looks a lot like $r!$, except that we remove all the factors up through $(r - n)$. In other words, the fraction is just

$$
	\frac{r!}{n!(r - n)!} = \binom{r}{n}.
$$

The expression on the right is a **binomial coefficient**, read as &#x201C;$r$ choose $n$&#x201D;. It&#x2019;s equal to the number of ways to choose $n$ objects out of a pile of $r$ objects, where the order in which you choose the $n$ doesn&#x2019;t matter. When $r$ is a real number and not necessarily a positive integer, $r!$ isn&#x2019;t defined, but we&#x2019;d really like to have a convenient notation for these Taylor coefficients. The easiest solution is to extend the definition of binomial coefficients to have a real number for the top value, allowing us to use them no matter the value of $r$.



### def generalized binomial coefficient
	
	Let $r$ be a real number and let $n$ be a positive integer. The **generalized binomial coefficient** $\binom{r}{n}$ is defined to be
	
	$$
		\binom{r}{n} = \frac{r(r - 1)(r - 2) \cdots (r - n + 1)}{n!}.
	$$

###



Now our Taylor coefficients are just generalized binomial coefficients &mdash; that is, the Maclaurin series for $(1 + x)^r$ is

$$
	\sum_{n = 0}^\infty \binom{r}{n} x^n.
$$

If $r$ is a positive integer, then $\binom{r}{n}$ will eventually contain a factor of $(r - (r + 1) + 1) = 0$ in the numerator, meaning the Maclaurin series will only have terms up to $x^r$. This makes perfect sense, though: when $r$ is a positive integer, $(1 + x)^r$ is a polynomial, so it shouldn&#x2019;t have an infinite series representation centered at $0$. It&#x2019;s the other values of $r$ that we&#x2019;d expect to have infinite representations.

So, when does this series converge? It&#x2019;s full of exponents and factorials, so let&#x2019;s try the ratio test. We have

$$
	\begin{align*}
		\lim_{n \to \infty} \left| \frac{\binom{r}{n + 1} x^{n + 1}}{\binom{r}{n} x^n} \right| &= \lim_{n \to \infty} \left| \frac{\frac{r(r - 1)(r - 2) \cdots (r - n)}{(n + 1)!} x^{n + 1}}{\frac{r(r - 1)(r - 2) \cdots (r - n + 1)}{n!} x^n} \right|\\
		&= \lim_{n \to \infty} \left| \frac{r(r - 1)(r - 2) \cdots (r - n) n! x^{n + 1}}{r(r - 1)(r - 2) \cdots (r - n + 1) (n + 1)! x^n} \right|\\
		&= \lim_{n \to \infty} \left| \frac{(r - n) x}{n + 1} \right|\\
		&= |x| \lim_{n \to \infty} \left| \frac{r - n}{n + 1} \right|\\
		&= |x|.
	\end{align*}
$$

Therefore, the series converges when $|x| < 1$, and so the interval of convergence is $(-1, 1)$.



### ex the Maclaurin series for $(1 + x)^r$
	
	Approximate $\frac{1}{\sqrt{2}}$ with a degree-4 Taylor polynomial and bound the error.
	
	At first glance, we might want to express this as $2^{-1/2}$ and use the Maclaurin series for $(1 + x)^{-1/2}$, but that would require setting $x = 1$, which is just barely outside the interval of convergence. Instead, we can write $\frac{1}{\sqrt{2}}$ as $\left( \frac{1}{2} \right)^{1/2}$. That way, we can use $(1 + x)^{1/2}$ with $x = -\frac{1}{2}$, which is in $(-1, 1)$.
	
	Let&#x2019;s calculate the degree-4 Maclaurin polynomial. We have
	
	$$
		\begin{align*}
			&\ \ \ \ \binom{1/2}{0} + \binom{1/2}{1} x + \binom{1/2}{2} x^2 + \binom{1/2}{3} x^3 + \binom{1/2}{4} x^4\\
			&= 1 + \frac{\frac{1}{2}}{1} x + \frac{\left(\frac{1}{2}\right)\left(-\frac{1}{2}\right)}{2!} x^2 + \frac{\left(\frac{1}{2}\right)\left(-\frac{1}{2}\right)\left(-\frac{3}{2}\right)}{3!} x^3 + \frac{\left(\frac{1}{2}\right)\left(-\frac{1}{2}\right)\left(-\frac{3}{2}\right)\left(-\frac{5}{2}\right)}{4!} x^4\\
			&= 1 + \frac{1}{2} x - \frac{1}{8} x^2 + \frac{1}{16} x^3 - \frac{5}{128} x^4.
		\end{align*}
	$$
	
	Plugging in $x = -\frac{1}{2}$ gives us
	
	$$
		1 - \frac{1}{4} - \frac{1}{32} - \frac{1}{128} - \frac{5}{2048} \approx .7085.
	$$
	
	To bound the error, we need to bound $|f^{(5)}(x)|$ on $\left(-\frac{1}{2}, 0\right)$. That derivative evaluates to
	
	$$
		\begin{align*}
			|f^{(5)}(x)| &= \left| \left(\frac{1}{2}\right)\left(-\frac{1}{2}\right)\left(-\frac{3}{2}\right)\left(-\frac{5}{2}\right)\left(-\frac{7}{2}\right)(1 + x)^{-9/2} \right|\\
			&= \left| \frac{\frac{105}{32}}{(1 + x)^{9/2}} \right|.
		\end{align*}
	$$
	
	How large can this be? The smaller that $1 + x$ is, the larger the expression will be, so the largest it could possibly get is when $x = -\frac{1}{2}$. Then we have
	
	$$
		|f^{(5)}(x)| \leq \left| \frac{\frac{105}{32}}{\left( \frac{1}{2} \right)^{9/2}} \right| \approx 74.246.
	$$
	
	By Taylor&#x2019;s theorem, the maximum error is then
	
	$$
		\frac{74.246}{5!} \left|\left(-\frac{1}{2}\right) - 0\right|^5 \approx .0193.
	$$
	
	This looks about right &mdash; the actual value of $\frac{1}{\sqrt{2}}$ is approximately $.7071$, and our estimate was $.7085$, so the error was about $.0014$, which is definitely less than $.0193$.
	
###

### exc the Maclaurin series for $(1 + x)^{3/2}$
	
	Express $(1 + x)^{3/2}$ as a Maclaurin series and determine the interval of convergence. Then approximate $1.5^{1.5}$ with a degree-3 Maclaurin polynomial and bound the error.
	
	**Solution:** Plugging this directly into the formula gives us
	
	$$
		(1 + x)^{3/2} = \sum_{n = 0}^\infty \binom{3/2}{n} x^n,
	$$
	
	with an interval of convergence of $(-1, 1)$. The degree $3$ polynomial is then
	
	$$
		\binom{3/2}{0} + \binom{3/2}{1} x + \binom{3/2}{2} x^2 + \binom{3/2}{3} x^3.
	$$
	
	We want to use $x = .5$, which is within the interval of convergence, and gives
	
	$$
		1 + \frac{3}{2} (.5) + \frac{\left(\frac{3}{2}\right)\left(\frac{1}{2}\right)}{2}(.5)^2 + \frac{\left(\frac{3}{2}\right)\left(\frac{1}{2}\right)\left(-\frac{1}{2}\right)}{6}(.5)^3 \approx 1.8359.
	$$
	
	To bound the error, we look at the fourth derivative of $(1 + x)^{3/2}$, which is $\left(\frac{3}{2}\right)\left(\frac{1}{2}\right)\left(-\frac{1}{2}\right)\left(-\frac{3}{2}\right)(1 + x)^{-5/2}$. The largest that can get in absolute value on $[-.5, .5]$ occurs when $x = -.5$, since $(1 + x)^{-5/2}$ is a decreasing function. We wind up with a bound of
	
	$$
		M = \left(\frac{3}{2}\right)\left(\frac{1}{2}\right)\left(-\frac{1}{2}\right)\left(-\frac{3}{2}\right)(.5)^{-5/2} = 3.182.
	$$
	
	Therefore, our bound on the remainder is
	
	$$
		\begin{align*}
			|R_3(x)| &\leq \frac{3.182}{4!}|x - 1|^4\\
			&\leq \frac{3.182}{4!}(.5)^4\\
			&= .0083.
		\end{align*}
	$$
	
###



## Taylor Series and Differential Equations

As we mentioned in section 8, power series have the excellent property of being differentiable term-by-term, and from an exercise last section, we saw how to use them to represent solutions to differential equations: by letting $y = \sum_{n = 0}^\infty c_n x^n$ be a generic Maclaurin series and setting $y' = y$, we were able to find a series representation for $e^x$. As we so often do in math, we&#x2019;ll now work in the opposite direction: if we&#x2019;re given a differential equation like $y' = y$ instead of setting it up ourselves, we can solve it for a Taylor series solution. In the best case, we&#x2019;ll recognize it as a function we know, but even if we don&#x2019;t, we&#x2019;ll still have solved the equation.



### ex solving a differential equation with power series
	
	Find a power series solution to $y'' = xy$.
	
	We&#x2019;re trying to solve for $y$ here, so let&#x2019;s take a generic power series $y = \sum_{n = 0}^\infty c_n x^n$. We&#x2019;re assuming that $y$ *has* a power series representation in the first place, which requires $y$ to be infinitely differentiable and also not be some sort of pathological case like $e^{-1/x^2}$. While very few functions actually meet these criteria, most of the ones we care about do, and so it&#x2019;s not too much to assume. Plus, the worst that can happen is that we figure out that no such representation exists and have to give up, so we might as well try.
	
	Getting everything in terms of power series tells us that
	
	$$
		\begin{align*}
			\frac{d^2}{dx^2} \sum_{n = 0}^\infty c_n x^n &= x \sum_{n = 0}^\infty c_n x^n\\
			\sum_{n = 2}^\infty c_n(n)(n - 1) x^{n - 2} &= \sum_{n = 0}^\infty c_n x^{n + 1}.
		\end{align*}
	$$
	
	In order to figure out what the $c_n$ should be, it helps to make the powers on $x$ match. To make them both $x^n$, we can start the left sum at $n = 0$ and the right sum at $n = 1$ to get
	
	$$
		\sum_{n = 0}^\infty c_{n + 2}(n + 2)(n + 1) x^n = \sum_{n = 1}^\infty c_{n - 1} x^n.
	$$
	
	Now we can see that $c_{n + 2}(n + 2)(n + 1) = c_{n - 1}$ for $n \geq 1$. For $n = 0$, the right sum has no $x^0$ term, so the equation is just $c_2(2)(1) = 0$. In total, our system of equations looks like this:
	
	$$
		\begin{align*}
			c_2 &= 0\\
			c_3 &= \frac{c_0}{3 \cdot 2}\\
			c_4 &= \frac{c_1}{4 \cdot 3}\\
			c_5 &= \frac{c_2}{5 \cdot 4}\\
			c_6 &= \frac{c_3}{6 \cdot 5}\\
			& \ \ \vdots
		\end{align*}
	$$
	
	This is a little tricky to parse, but it&#x2019;s not too terrible. First of all, every $c_n$ satisfies $c_n = \frac{c_{n - 3}}{n(n-1)}$, so $c_5 = \frac{c_2}{20} = 0$, and similarly, $c_8 = c_{11} = \cdots = 0$. What about the others? Well, nothing tells us anything about $c_0$ or $c_1$, so we&#x2019;ll have to leave those as parameters (more on that in a moment). For $c_3, c_6, c_9$, and so on, we have
	
	$$
		\begin{align*}
			c_3 &= \frac{c_0}{3 \cdot 2}\\
			c_6 &= \frac{c_3}{6 \cdot 5} = \frac{c_0}{6 \cdot 5 \cdot 3 \cdot 2}\\
			c_9 &= \frac{c_6}{9 \cdot 8} = \frac{c_0}{9 \cdot 8 \cdot 6 \cdot 5 \cdot 3 \cdot 2}\\
			& \ \ \vdots
		\end{align*}
	$$
	
	This is a pretty weird configuration. If we really wanted to, we could express this as a sort of &#x201C;gappy factorial&#x201D; by starting with $n!$ and dividing by one more than each multiple of $3$. That&#x2019;s a mess best left avoided, though &mdash; let&#x2019;s look at the pattern for $c_1$ and not worry about getting an explicit formula.
	
	$$
		\begin{align*}
			c_4 &= \frac{c_1}{4 \cdot 3}\\
			c_7 &= \frac{c_4}{7 \cdot 6} = \frac{c_1}{7 \cdot 6 \cdot 4 \cdot 3}\\
			c_{10} &= \frac{c_7}{10 \cdot 9} = \frac{c_1}{10 \cdot 9 \cdot 7 \cdot 6 \cdot 4 \cdot 3}\\
			& \ \ \vdots
		\end{align*}
	$$
	
	In total, our power series power series expression for $y$ is
	
	$$
		\begin{align*}
			y &= c_0 + c_1 x + \frac{c_0}{3 \cdot 2} x^3 + \frac{c_1}{4 \cdot 3} x^4 + \frac{c_0}{6 \cdot 5 \cdot 3 \cdot 2} x^6 + \frac{c_1}{7 \cdot 6 \cdot 4 \cdot 3} x^7 + \cdots\\
			&= c_0 \left( 1 + \frac{x^3}{3 \cdot 2} + \frac{x^6}{6 \cdot 5 \cdot 3 \cdot 2} + \cdots \right) + c_1 \left( x + \frac{x^4}{4 \cdot 3} + \frac{x^7}{7 \cdot 6 \cdot 4 \cdot 3} + \cdots \right).
		\end{align*}
	$$
	
	The presence of the $c_0$ and $c_1$ indicate that there are two free variables &mdash; we can take them to be anything we like, and the equation $y'' = xy$ will still be satisfied. If we&#x2019;re given initial conditions, say $y(0) = 1$ and $y'(0) = 2$, then we can solve for them. In this particular case, we would have $y(0) = c_0 = 1$, and $y'(0) = c_1 = 2$.
	
###

### exc solving a differential equation with power series
	
	Find a power series solution to the differential equation $y'' = \frac{y}{x}$.

###



## Taylor Series and Integrals

We&#x2019;ve seen this application before too: power series integrate term-by-term, so if we&#x2019;re unable to solve an integral with our usual techniques, we can convert the function to a series and integrate that.



### ex evaluating an integral with power series
	
	Approximate $\int_0^1 e^{-x^2}\,dx$ to within $.001$ of its true value.
	
	This is a famously difficult integral &mdash; it&#x2019;s usually the first example of one that isn&#x2019;t expressible in terms of elementary functions. In other words, there is no combination of polynomials, trig functions, exponentials, and logs whose derivative is $e^{-x^2}$. None of the main four integration techniques works here &mdash; $u$-sub would want $u = -x^2$, but $du = -2x\,dx$ isn&#x2019;t present anywhere, integration by parts needs two things multiplied together to work properly, and trig sub and partial fractions both need setups that aren&#x2019;t present here. Despite all that, $e^{-x^2}$ has a perfectly resaonable Maclaurin series representation, and we can just integrate that. First of all, the series for $e^x$ is
	
	$$
		e^x = \sum_{n = 0}^\infty \frac{x^n}{n!},
	$$
	
	which is valid on $(-\infty, \infty)$, i.e. no matter what $x$ is. We need to to plug $-x^2$ in for $x$, which results in
	
	$$
		\begin{align*}
			e^{-x^2} &= \sum_{n = 0}^\infty \frac{(-x^2)^n}{n!}\\
			&= \sum_{n = 0}^\infty (-1)^n \frac{x^{2n}}{n!}\\
			&= -1 + x^2 - \frac{x^4}{2!} + \frac{x^6}{3!} - \cdots.
		\end{align*}
	$$
	
	This series representation is valid whenever $-x^2$ is in the interval of convergence of the original series. Since that was $(-\infty, \infty)$, $-x^2$ is always in the interval of convergence, so the interval of convergence of this new series is also $(-\infty, \infty)$.
	
	Now we need to integrate the new series term by term. This amounts to just applying the power rule:
	
	$$
		\begin{align*}
			\int e^{-x^2}\,dx &= \int \left( \sum_{n = 0}^\infty (-1)^n \frac{x^{2n}}{n!} \right)\,dx\\
			&= \sum_{n = 0}^\infty \left( \int (-1)^n \frac{x^{2n}}{n!}\,dx \right) + C\\
			&= \sum_{n = 0}^\infty \left( \frac{(-1)^n}{n!} \int x^{2n}\,dx \right) + C\\
			&= \sum_{n = 0}^\infty \left( \frac{(-1)^n}{n!} \frac{x^{2n + 1}}{2n + 1} \right) + C.
		\end{align*}
	$$
	
	We&#x2019;ll finish the problem by evaluating the definite integral, but this is already pretty wild: while it&#x2019;s definitely preferable to have a closed form of a function rather than a series representation, we were able to bypass the intractable integral immediately by passing to a Maclaurin series. And since integrating doesn&#x2019;t affect the interval of convergence, this is still equal to $e^{-x^2}$ for all values of $x$. We just need to use $x = 0$ and $x = 1$: specifically,
	
	$$
		\begin{align*}
			\int_0^1 e^{-x^2}\,dx &= \left. \left[ \sum_{n = 0}^\infty \left( \frac{(-1)^n}{n!} \frac{x^{2n + 1}}{2n + 1} \right) + C \right] \right|_0^1\\
			&= \left( \sum_{n = 0}^\infty \left( \frac{(-1)^n}{n!} \frac{1^{2n + 1}}{2n + 1} \right) + C \right) - \left( \sum_{n = 0}^\infty \left( \frac{(-1)^n}{n!} \frac{0^{2n + 1}}{2n + 1} \right) + C \right)\\
			&= \sum_{n = 0}^\infty \left( \frac{(-1)^n}{n!} \frac{1}{2n + 1} \right).
		\end{align*}
	$$
	
	We can&#x2019;t use Taylor&#x2019;s theorem to bound the error, since we don&#x2019;t know a closed form of the function that generates this series. However, in a happy coincidence, this is an alternating series with decreasing terms, so we can actually use the alternating series test! The remainder $R_N$ is bounded by
	
	$$
		|R_N| \leq \left| \frac{1}{(N + 1)!} \cdot \frac{1}{2(N + 1) + 1} \right|,
	$$
	
	so if we want that to be less than $.001$, we just need to find a large enough $N$. The factorial makes this tricky to solve explicitly, but plugging in a few values, we find that $N = 4$ bounds $|R_4|$ by $.00076 < .001$. We&#x2019;ll therefore use $S_4$ as our approximation, which is
	
	$$
		\begin{align*}
			S_4 &= \sum_{n = 0}^4 \left( \frac{(-1)^n}{n!} \frac{1}{2n + 1} \right)\\
			&= \frac{5651}{7560}\\
			&\approx .7475.
		\end{align*}
	$$
	
	Sure enough, the actual value is about $.7468$. As an interesting side note, the integral $\int_{-\infty}^\infty e^{-x^2}\,dx$ is actually equal to $\sqrt{\pi}$, and is also the graph of the Normal distribution in statistics. If you&#x2019;re taking multivariable calculus, you&#x2019;ll see how to compute the $\sqrt{\pi}$ value exactly, and if you take or have taken statistics, you&#x2019;ll see $\sqrt{\pi}$ show up in the formula for Normal distribution functions &mdash; this is a normalization factor that makes the total integral become exactly $1$, which is necessary for probabilities to make sense.
	
###

### exc evaluating an integral with power series
	
	Approximate $\int_0^1 \frac{\sin(x)}{x}\,dx$ to within $.001$ of its true value.
	
###



We&#x2019;ve made it! Over the past ten weeks, we&#x2019;ve developed a comprehensive theory of series, both of numbers and of functions, and understood how, why, and when they converge, and in many cases their values. The applications of series representations are as wide-ranging as the applications of the functions they represent, and they arise in nearly every field that relies even slightly on math, from computer science to physics. Thank you for being a part of this class &mdash; I hope to see you in future courses!



### nav-buttons



<script>
	if (typeof Page === "undefined")
	{
		if (window.location.search !== "")
		{
			window.location.replace("/index-testing.html?page=" + encodeURIComponent(window.location.pathname) + "&" + window.location.search.slice(1));
		}
		
		else
		{
			window.location.replace("/index-testing.html?page=" + encodeURIComponent(window.location.pathname));
		}
	}
	
	
	
	Page.settings = 
	{
		"parent_list": "/teaching/uo/253/notes"
	};
	
	Page.load();
</script>